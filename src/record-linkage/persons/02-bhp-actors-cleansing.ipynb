{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geovpylib.utils as u\n",
    "import geovpylib.analysis as a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BHP actor cleansing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is tool cleanse the list of prepared BHP actors according to the entity recognition that has been made by the record linkage + the manual look at the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp_actors = u.read_df('../../../data/prepared/bhp_actors.csv')\n",
    "bhp_actors.drop(columns=['first_name', 'last_name', 'certainty_birth', 'certainty_death'], inplace=True)\n",
    "\n",
    "# u.infos(bhp_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_recognition = u.read_df('../../../reports/bhp_entity_recognition_mp.csv')\n",
    "entity_recognition = entity_recognition[['pk_l', 'pk_r', 'chosen_one_pk', 'please_import', 'remarks']]\n",
    "\n",
    "# u.infos(entity_recognition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate entity recognitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also are going to create a black list file, so that we know which actor has to be deleted\n",
    "blacklist = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"complémentaires\" recognitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the goal is to merge the two entities into the master one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going, to do a dataframe for each information, and then left join them all, so that it can be added to the bhp_actors dataframe\n",
    "names = []\n",
    "definitions = []\n",
    "genders = []\n",
    "birth_years = []\n",
    "death_years = []\n",
    "\n",
    "# Select only information we need from the entity recognition file\n",
    "complementaries = entity_recognition[entity_recognition['remarks'] == 'complémentaires'].copy()\n",
    "complementaries.rename(columns={'chosen_one_pk': 'keep'}, inplace=True)\n",
    "complementaries['erase'] = [row['pk_r'] if row['pk_l'] == row['keep'] else row['pk_l'] for _,row in complementaries.iterrows()]\n",
    "complementaries.drop(columns=['please_import', 'remarks', 'pk_l', 'pk_r'], inplace=True)\n",
    "\n",
    "\n",
    "# Apply the \"complémentaire\" logic\n",
    "for _, row in complementaries.iterrows():\n",
    "    keep = bhp_actors[bhp_actors['pk'] == row['keep']]\n",
    "    erase = bhp_actors[bhp_actors['pk'] == row['erase']]\n",
    "\n",
    "    selection = pd.concat([keep, erase])\n",
    "\n",
    "    # Names\n",
    "    for name in selection['name'].unique():\n",
    "        names.append({'pk': row['keep'], 'name': name})\n",
    "\n",
    "    # Definition\n",
    "    for _, row2 in selection[['definition', 'definition_lang']].drop_duplicates().iterrows():\n",
    "        definitions.append({'pk': row['keep'], 'definition': row2['definition'], 'definition_lang': row2['definition_lang']})\n",
    "\n",
    "    # Gender\n",
    "    gender = keep['gender'].unique().tolist()[0]\n",
    "    if pd.isna(gender): gender = erase['gender'].unique().tolist()[0]\n",
    "    genders.append({'pk': row['keep'], 'gender': gender})\n",
    "\n",
    "    # Birth year\n",
    "    birth_year = keep['birth_year'].iloc[0]\n",
    "    if pd.isna(birth_year): birth_year = erase['birth_year'].iloc[0]\n",
    "    birth_years.append({'pk': row['keep'], 'birth_year': birth_year})\n",
    "\n",
    "    # Death year\n",
    "    death_year = keep['death_year'].iloc[0]\n",
    "    if pd.isna(death_year): death_year = erase['death_year'].iloc[0]\n",
    "    death_years.append({'pk': row['keep'], 'death_year': death_year})\n",
    "   \n",
    "    # Black list\n",
    "    blacklist.append(row['erase'])\n",
    "\n",
    "# Into dataframes\n",
    "names = pd.DataFrame(data=names)\n",
    "definitions = pd.DataFrame(data=definitions)\n",
    "genders = pd.DataFrame(data=genders)\n",
    "birth_years = pd.DataFrame(data=birth_years)\n",
    "death_years = pd.DataFrame(data=death_years)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"données pauvres\" recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are simply goind to blacklist both entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only information we need from the entity recognition file\n",
    "poor_data = entity_recognition[entity_recognition['remarks'] == 'données pauvres ou incohérentes'].copy()\n",
    "poor_data.rename(columns={'pk_l': 'pk1', 'pk_r': 'pk2'}, inplace=True)\n",
    "poor_data = poor_data[['pk1', 'pk2']]\n",
    "\n",
    "blacklist = np.unique(blacklist + poor_data['pk1'].tolist() + poor_data['pk2'].tolist()).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"doute\" recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these data, actually there is nothing to do: both entities have to be imported as such. Should they be linked via a \"has to be merged\" property?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"prénom inconnu\" recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same, if we have no first name, entities should be created separatly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"triplon louis palandre 63414\" recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have only one tripple recognition. So in order to save time, we will handle this one manually.\n",
    "\n",
    "So for the code, it has to be (for both of the entities) has to be blacklisted.\n",
    "\n",
    "We can do that because we made sure that the only difference between the 3 entities is their definition.\n",
    "\n",
    "So in the end, the work that would need to be done is to add the definition of entity 63405 and 63384 to Louis Palandre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"empty\" recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the other recognition, if we do not have a `chosen_one_pk`, it means that we keep both of the entity. As previously explain, it results in doing nothing here.\n",
    "\n",
    "However, when there is a `chosen_one_pk`, we have to blacklist the not chosen one, and do nothing with the chosen one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = entity_recognition[pd.isna(entity_recognition['remarks'])]\n",
    "empty = empty[pd.notna(empty['chosen_one_pk'])]\n",
    "\n",
    "empty['erase'] = [row['pk_l'] if row['chosen_one_pk'] == row['pk_r'] else row['pk_r'] for _, row in empty.iterrows()]\n",
    "blacklist = np.unique(blacklist + empty['erase'].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result from entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk</th>\n",
       "      <th>name</th>\n",
       "      <th>definition</th>\n",
       "      <th>definition_lang</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>death_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22087</td>\n",
       "      <td>septimus andreas fabricius</td>\n",
       "      <td>Mdecin  Nuremberg</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1641</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22087</td>\n",
       "      <td>septimus andreas fabricius</td>\n",
       "      <td>Arzt</td>\n",
       "      <td>deu</td>\n",
       "      <td>Male</td>\n",
       "      <td>1641</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22087</td>\n",
       "      <td>s. a. fabricius</td>\n",
       "      <td>Mdecin  Nuremberg</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1641</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22087</td>\n",
       "      <td>s. a. fabricius</td>\n",
       "      <td>Arzt</td>\n",
       "      <td>deu</td>\n",
       "      <td>Male</td>\n",
       "      <td>1641</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22620</td>\n",
       "      <td>jean deriennes</td>\n",
       "      <td>*Dieppe 1591, La Flche 5.VI.1662. Jsuite, prof...</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1591</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>60554</td>\n",
       "      <td>louis gabriel escher</td>\n",
       "      <td>Industriel mtallurgiste n le 27 novembre 1819 ...</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1819</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>60554</td>\n",
       "      <td>louis gabriel oescher</td>\n",
       "      <td>Industriel mtallurgiste. Associ  Louis Charles...</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1819</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>60554</td>\n",
       "      <td>louis gabriel oescher</td>\n",
       "      <td>Industriel mtallurgiste n le 27 novembre 1819 ...</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1819</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2291</td>\n",
       "      <td>toms maluenda</td>\n",
       "      <td>*Jtiva (Valence) 1566, 7.V.1628. Clbre dominic...</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1565</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2291</td>\n",
       "      <td>toms malvenda</td>\n",
       "      <td>*Jtiva (Valence) 1566, 7.V.1628. Clbre dominic...</td>\n",
       "      <td>fra</td>\n",
       "      <td>Male</td>\n",
       "      <td>1565</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pk                        name  \\\n",
       "0    22087  septimus andreas fabricius   \n",
       "1    22087  septimus andreas fabricius   \n",
       "2    22087             s. a. fabricius   \n",
       "3    22087             s. a. fabricius   \n",
       "4    22620              jean deriennes   \n",
       "..     ...                         ...   \n",
       "145  60554        louis gabriel escher   \n",
       "146  60554       louis gabriel oescher   \n",
       "147  60554       louis gabriel oescher   \n",
       "148   2291               toms maluenda   \n",
       "149   2291               toms malvenda   \n",
       "\n",
       "                                            definition definition_lang gender  \\\n",
       "0                                    Mdecin  Nuremberg             fra   Male   \n",
       "1                                                 Arzt             deu   Male   \n",
       "2                                    Mdecin  Nuremberg             fra   Male   \n",
       "3                                                 Arzt             deu   Male   \n",
       "4    *Dieppe 1591, La Flche 5.VI.1662. Jsuite, prof...             fra   Male   \n",
       "..                                                 ...             ...    ...   \n",
       "145  Industriel mtallurgiste n le 27 novembre 1819 ...             fra   Male   \n",
       "146  Industriel mtallurgiste. Associ  Louis Charles...             fra   Male   \n",
       "147  Industriel mtallurgiste n le 27 novembre 1819 ...             fra   Male   \n",
       "148  *Jtiva (Valence) 1566, 7.V.1628. Clbre dominic...             fra   Male   \n",
       "149  *Jtiva (Valence) 1566, 7.V.1628. Clbre dominic...             fra   Male   \n",
       "\n",
       "     birth_year  death_year  \n",
       "0          1641        1705  \n",
       "1          1641        1705  \n",
       "2          1641        1705  \n",
       "3          1641        1705  \n",
       "4          1591        1662  \n",
       "..          ...         ...  \n",
       "145        1819        1887  \n",
       "146        1819        1887  \n",
       "147        1819        1887  \n",
       "148        1565        1628  \n",
       "149        1565        1628  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['pk'] = entity_recognition['chosen_one_pk'].dropna().tolist()\n",
    "\n",
    "result = result.merge(names, on='pk', how='left')\n",
    "result = result.merge(definitions, on='pk', how='left')\n",
    "result = result.merge(genders, on='pk', how='left')\n",
    "result = result.merge(birth_years, on='pk', how='left')\n",
    "result = result.merge(death_years, on='pk', how='left')\n",
    "\n",
    "result.dropna(subset=['name', 'definition', 'definition_lang', 'gender', 'birth_year', 'death_year'], inplace=True)\n",
    "result.drop_duplicates(inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "u.parse_df(result)\n",
    "\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black list length:  438\n"
     ]
    }
   ],
   "source": [
    "print('Black list length: ', len(blacklist))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make BHP actors list clean again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning shape: (70193, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Before cleaning shape:', bhp_actors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop from blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing blacklist shape: (69741, 7)\n"
     ]
    }
   ],
   "source": [
    "bhp_actors = bhp_actors[[pk not in blacklist for pk in bhp_actors['pk']]]\n",
    "\n",
    "print('After removing blacklist shape:', bhp_actors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop aggregated entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing aggregated entities shape: (69687, 7)\n"
     ]
    }
   ],
   "source": [
    "bhp_actors = bhp_actors[[pk not in result['pk'].tolist() for pk in bhp_actors['pk']]]\n",
    "\n",
    "print('After removing aggregated entities shape:', bhp_actors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add aggregated entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding aggregated entities shape: (69837, 7)\n"
     ]
    }
   ],
   "source": [
    "bhp_actors = pd.concat([bhp_actors, result])\n",
    "\n",
    "print('After adding aggregated entities shape:', bhp_actors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.save_df(bhp_actors, '../../../data/prepared/bhp_actors_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
