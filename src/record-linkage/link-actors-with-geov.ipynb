{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize already existing persons in Geovistory from the BHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import toolkit as tk\n",
    "\n",
    "from splink.duckdb.duckdb_linker import DuckDBLinker\n",
    "from splink.charts import waterfall_chart\n",
    "import splink.duckdb.duckdb_comparison_library as cl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to load Geovistory's data on one side, and BHP's data on the other, the goal being of identifing exiting persons of the BHP into Geovistory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_geov = pd.read_csv('../../data/persons-geov.csv', sep=';')\n",
    "tk.set_types(persons_geov, {'name':'string', 'gender':'string', 'birth_year':'int', 'death_year':'int'})\n",
    "persons_geov.reset_index(inplace=True)\n",
    "\n",
    "print('Geovistory\\'s persons:')\n",
    "tk.infos(persons_geov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_bhp = pd.read_csv('../../data/persons-bhp.csv', sep=';')\n",
    "tk.set_types(persons_bhp, {'name':'string', 'gender':'string', 'birth_year':'int', 'death_year':'int'})\n",
    "persons_bhp.reset_index(inplace=True)\n",
    "\n",
    "print('BHP\\'s persons:')\n",
    "tk.infos(persons_bhp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction generation blocking rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the set blocking rules to generate the pairwise comparisons; in other words all record couples that do not statisfied at least one of those rules will not be considered in final predictions. \n",
    "\n",
    "This is so to avoid to have to do all comparisons which would be heavy (would take forever) for a computer to do. In our case it would be length of BHP data times length of Geovistory data times number of column, so 62k times 147k times 4 = 37G comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocking_rules_predictions = [\n",
    "    \"l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3\",\n",
    "    \"l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3\",\n",
    "]\n",
    "\n",
    "for br in blocking_rules_predictions:\n",
    "    print(f\"Blocking rule: <{br}>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set multiple comparison rules, which describe how the comparison will be executed on 2 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = [\n",
    "    # cl.levenshtein_at_thresholds(\"name\", 1), # Because we want matches with only a typo be more close to a matching than is it is another spelling\n",
    "    cl.levenshtein_at_thresholds(\"name\", 3), # If a name has another spelling (like phonetics)\n",
    "    cl.exact_match(\"gender\"), # Because we have controlled vocabulary for the gender\n",
    "    cl.exact_match(\"birth_year\"), # This takes the assumption that there is no typo possible on birth year\n",
    "    cl.exact_match(\"death_year\"), # This takes the assumption that there is no typo possible on death year\n",
    "]\n",
    "\n",
    "for br in comparisons:\n",
    "    print(f\"{br}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"link_type\": \"link_only\", # Describe the fact that we want to merge 2 dataframe and that one may already have some of the second one.\n",
    "    \"unique_id_column_name\": \"index\", # Each dataframe has to have a unique key for each line, here we tell Splink, what is the name of the column\n",
    "    \"blocking_rules_to_generate_predictions\": blocking_rules_predictions,\n",
    "    \"comparisons\": comparisons,\n",
    "    \"retain_matching_columns\": True, # To have waterfall charts\n",
    "    \"retain_intermediate_calculation_columns\": True, # To have waterfall charts\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chart displays how much final comparisons the model will have to predict. Basically this total number will be an upper boundary of the final prediction table length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = DuckDBLinker(\n",
    "    [persons_geov, persons_bhp], \n",
    "    settings, \n",
    "    input_table_aliases=[\"geov\", \"bhp\"] # To have custom names in comparison table\n",
    ")\n",
    "\n",
    "linker.cumulative_num_comparisons_from_blocking_rules_chart()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training blocking rule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train our model, we need to estimate the $m$ and $u$ parameters of the Fellegi-Sunter model associated with and EM algorithm (more of that [here](https://www.robinlinacre.com/maths_of_fellegi_sunter/) and [here](https://www.robinlinacre.com/em_intuition/)).\n",
    "\n",
    "The $u$ parameter will be estimated using random sampling. This is valid (as explained [here](https://moj-analytical-services.github.io/splink/linker.html#splink.linker.Linker.estimate_u_using_random_sampling)) because there is a very low probability for 2 randomly picked records to be the same person. We just have to make sure that the sample taken is large enough to correctly train this parameter.\n",
    "\n",
    "For the $m$ parameter, to have a powerfull model, we can not take such an hypothesis; we need to train the model (statistically) on the data. As before, since we can not take the full data, we need to filter out comparisons so that it is manageable in a reasonnable time. See the next display to see rules we took. \n",
    "\n",
    "How to interpret those rules? Basically, for all column (present in the comparison rules above) not being in a training blocking rules, we will estimate the $m$ parameter on pairwise comparisons validated by the rule. In other word, if the `gender` column does not appear in the rule, it means that the $m$ parameter for the column `gender` will be trained (calculated) on all the pairwaise comparisons remaining after beeing filter by the rule.\n",
    "\n",
    "This also implies that all columns MUST not appear in at least one rule, otherwise we can never train the $m$ parameter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training blocking rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocking_rules_training = [\n",
    "    \"l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3\",\n",
    "    \"l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3\",\n",
    "    \"l.birth_year = r.birth_year and l.death_year = r.death_year\",\n",
    "]\n",
    "\n",
    "for br in blocking_rules_training:\n",
    "    print(f\"Blocking rule: <{br}>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = linker.estimate_u_using_random_sampling(target_rows=2e7)\n",
    "\n",
    "for br in blocking_rules_training:\n",
    "    z = linker.estimate_parameters_using_expectation_maximisation(br)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What has been learned?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model trained, first, lets look at what did the model learn about our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe how a response level (on the left) influences the matching probability.\n",
    "\n",
    "More particularly we observe that the gender has a very low influence on the result, just on the contrary of the name."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persons identified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table is an extract of the 50 most probable matchings.\n",
    "Each line represents a pairwise comparison. We can see the probability (computed by the trained model), and each column put aside another in order to be more human readable. A copy is available as a CSV table in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = linker.predict(threshold_match_probability=0.9)\n",
    "results = linker.predict()\n",
    "results_df = results.as_pandas_dataframe().sort_values(by='match_probability', ascending=False)\n",
    "print('Result number:', len(results_df))\n",
    "\n",
    "readable = results_df[['match_probability', 'source_dataset_l', 'source_dataset_r', 'index_l', 'index_r', 'name_l', 'name_r', 'gender_l', 'gender_r', 'birth_year_l', 'birth_year_r', 'death_year_l', 'death_year_r']].copy()\n",
    "readable.rename(columns={\n",
    "    'match_probability':'proba', \n",
    "    'index_l': 'id_bhp', \n",
    "    'index_r': 'pk_geov',\n",
    "    'name_l': 'bhp_name',\n",
    "    'name_r': 'geov_name',\n",
    "    'gender_l': 'bhp_gender',\n",
    "    'gender_r': 'geov_gender',\n",
    "    'birth_year_l': 'bhp_birth_year',\n",
    "    'birth_year_r': 'geov_birth_year',\n",
    "    'death_year_l': 'bhp_death_year',\n",
    "    'death_year_r': 'geov_death_year'\n",
    "}, inplace=True)\n",
    "tk.set_types(readable, {\n",
    "    'bhp_birth_year': 'int',\n",
    "    'geov_birth_year': 'int',\n",
    "    'bhp_death_year': 'int',\n",
    "    'geov_death_year': 'int',\n",
    "})\n",
    "readable['proba'] = [tk.percent(p) for p in readable['proba']]\n",
    "readable.drop(columns=['source_dataset_l', 'source_dataset_r'], inplace=True)\n",
    "\n",
    "readable.to_csv('../../data/bhp_geov_entity_recognition.csv', sep=\";\", index=False, quoting=2)\n",
    "readable.head(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chart gives us details about a particular pairwise comparison. The example can be changed with the bottom slider. More information are available on mouse over the different elements.\n",
    "\n",
    "This chart helps us understand why the model answered the provided response.\n",
    "\n",
    "For conveniance, only the first 1000 comparisons are available through this chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_to_plot = results_df.head(1000).to_dict(orient=\"records\")\n",
    "linker.waterfall_chart(records_to_plot, filter_nulls=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
