{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Connecting to STAGING Database ... Connected!\n"
     ]
    }
   ],
   "source": [
    "# %load ~/Desktop/geovpylib/heading.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "env = 'stag'\n",
    "pk_project = 11850066\n",
    "execute = True\n",
    "metadata_str = 'collective-actors'\n",
    "import_manner = 'one-shot' # 'batch'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "import plotly.express as px\n",
    "\n",
    "import geovpylib.analysis as a\n",
    "import geovpylib.database as db\n",
    "import geovpylib.queries as q\n",
    "import geovpylib.pks as pks\n",
    "import geovpylib.sparql as sparql\n",
    "import geovpylib.utils as u\n",
    "\n",
    "eta = u.Eta()\n",
    "\n",
    "# db.connect_external(os.getenv(''))\n",
    "db.connect_geovistory(env, pk_project, execute)\n",
    "db.set_metadata({'import-id': datetime.today().strftime('%Y%m%d') + '-' + metadata_str})\n",
    "db.set_insert_manner(import_manner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import collective actors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BHP infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Connecting to PGSQL Database ... Connected!\n"
     ]
    }
   ],
   "source": [
    "db.connect_external(os.environ.get('YELLOW_BHP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (22009, 10) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_collective_actor</th>\n",
       "      <th>notes_begin</th>\n",
       "      <th>certainty_begin</th>\n",
       "      <th>notes_end</th>\n",
       "      <th>certainty_end</th>\n",
       "      <th>notes</th>\n",
       "      <th>fk_abob_type_collective_actor</th>\n",
       "      <th>begin_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>concat_standard_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14725</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1051</td>\n",
       "      <td>1969</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Parti Socialiste (PS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9712</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1051</td>\n",
       "      <td>1945</td>\n",
       "      <td>1998</td>\n",
       "      <td>Conseil national du patronat français (CNPF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13649</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Parlement des États de Bourgogne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14723</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1051</td>\n",
       "      <td>1477</td>\n",
       "      <td>1789</td>\n",
       "      <td>Bailliage de Chalon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14726</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1051</td>\n",
       "      <td>1971</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Université Paris 1 (Panthéon-Sorbonne)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_collective_actor  notes_begin  certainty_begin  notes_end  \\\n",
       "0                14725            2                1       <NA>   \n",
       "1                 9712            2                1          2   \n",
       "2                13649         <NA>                1       <NA>   \n",
       "3                14723         <NA>             <NA>       <NA>   \n",
       "4                14726            2                1       <NA>   \n",
       "\n",
       "   certainty_end notes  fk_abob_type_collective_actor  begin_year  end_year  \\\n",
       "0           <NA>  <NA>                           1051        1969      <NA>   \n",
       "1              1  <NA>                           1051        1945      1998   \n",
       "2              1  <NA>                           <NA>        <NA>      <NA>   \n",
       "3           <NA>  <NA>                           1051        1477      1789   \n",
       "4           <NA>  <NA>                           1051        1971      <NA>   \n",
       "\n",
       "                           concat_standard_name  \n",
       "0                         Parti Socialiste (PS)  \n",
       "1  Conseil national du patronat français (CNPF)  \n",
       "2              Parlement des États de Bourgogne  \n",
       "3                           Bailliage de Chalon  \n",
       "4        Université Paris 1 (Panthéon-Sorbonne)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (24429, 11) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_collective_actor_name</th>\n",
       "      <th>is_standard_name</th>\n",
       "      <th>name</th>\n",
       "      <th>lang_iso</th>\n",
       "      <th>comment_begin_year</th>\n",
       "      <th>comment_end_year</th>\n",
       "      <th>notes</th>\n",
       "      <th>fk_collective_actor</th>\n",
       "      <th>fk_abob_coac_name_type</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Collège des Jésuites de Genova</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Collège romain</td>\n",
       "      <td>fra</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>Compagnie de Jésus</td>\n",
       "      <td>fra</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>Congrégation de l'Index</td>\n",
       "      <td>fra</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>Congrégation de l'Inquisition</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_collective_actor_name  is_standard_name                            name  \\\n",
       "0                         5              True  Collège des Jésuites de Genova   \n",
       "1                         6              True                  Collège romain   \n",
       "2                         8              True              Compagnie de Jésus   \n",
       "3                         9              True         Congrégation de l'Index   \n",
       "4                        10              True   Congrégation de l'Inquisition   \n",
       "\n",
       "  lang_iso comment_begin_year comment_end_year notes  fk_collective_actor  \\\n",
       "0     <NA>               <NA>             <NA>  <NA>                   10   \n",
       "1      fra               <NA>             <NA>  <NA>                   11   \n",
       "2      fra               <NA>             <NA>  <NA>                   13   \n",
       "3      fra               <NA>             <NA>  <NA>                   14   \n",
       "4     <NA>               <NA>             <NA>  <NA>                   15   \n",
       "\n",
       "   fk_abob_coac_name_type begin_date end_date  \n",
       "0                    <NA>       <NA>     <NA>  \n",
       "1                    <NA>       <NA>     <NA>  \n",
       "2                    <NA>       <NA>     <NA>  \n",
       "3                    <NA>       <NA>     <NA>  \n",
       "4                    <NA>       <NA>     <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (16687, 6) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_collective_actor_text_property</th>\n",
       "      <th>property_type</th>\n",
       "      <th>lang_iso_code</th>\n",
       "      <th>text</th>\n",
       "      <th>notes</th>\n",
       "      <th>fk_collective_actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8718</td>\n",
       "      <td>notice</td>\n",
       "      <td>ita</td>\n",
       "      <td>Comunità valdesi impiantatesi in Calabria dal ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8679</td>\n",
       "      <td>notice</td>\n",
       "      <td>fra</td>\n",
       "      <td>Chambre syndicale patronale</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5857</td>\n",
       "      <td>notice</td>\n",
       "      <td>fra</td>\n",
       "      <td>Chambre syndicale patronale</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8678</td>\n",
       "      <td>notice</td>\n",
       "      <td>fra</td>\n",
       "      <td>Chambre syndicale patronale</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8680</td>\n",
       "      <td>notice</td>\n",
       "      <td>fra</td>\n",
       "      <td>Syndicat patronal</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_collective_actor_text_property property_type lang_iso_code  \\\n",
       "0                               8718        notice           ita   \n",
       "1                               8679        notice           fra   \n",
       "2                               5857        notice           fra   \n",
       "3                               8678        notice           fra   \n",
       "4                               8680        notice           fra   \n",
       "\n",
       "                                                text notes  \\\n",
       "0  Comunità valdesi impiantatesi in Calabria dal ...  <NA>   \n",
       "1                        Chambre syndicale patronale  <NA>   \n",
       "2                        Chambre syndicale patronale  <NA>   \n",
       "3                        Chambre syndicale patronale  <NA>   \n",
       "4                                  Syndicat patronal  <NA>   \n",
       "\n",
       "   fk_collective_actor  \n",
       "0                14779  \n",
       "1                14283  \n",
       "2                 9139  \n",
       "3                14709  \n",
       "4                14711  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coac = u.read_df('../../data/bhp/collective-actor.csv').rename(columns={'notes':'notes_coac', 'begin_year':'begin_year_coac', 'end_year':'end_year_coac'}).drop(columns=['concat_standard_name'])\n",
    "coac_name = u.read_df('../../data/bhp/collective-actor-name.csv').rename(columns={'notes':'notes_name', 'lang_iso':'lang_name', 'comment_begin_year':'comment_begin_year_name', 'comment_end_year':'comment_end_year_name', 'begin_date':'begin_date_name', 'end_date':'end_date_name'})\n",
    "coac_text_property = u.read_df('../../data/bhp/collective-actor-text-property.csv').rename(columns={'notes':'notes_text_prop', 'lang_iso_code':'lang_text_prop'})\n",
    "\n",
    "coacs = coac.merge(coac_name, left_on='pk_collective_actor', right_on='fk_collective_actor', how='left').drop(columns=['fk_collective_actor', 'pk_collective_actor_name'])\n",
    "coacs = coacs.merge(coac_text_property, left_on='pk_collective_actor', right_on='fk_collective_actor', how='left').drop(columns=['fk_collective_actor', 'pk_collective_actor_text_property'])\n",
    "coacs['begin_date_name'] = [u.parse_tuple_date(d) for d in coacs['begin_date_name']]\n",
    "coacs['end_date_name'] = [u.parse_tuple_date(d) for d in coacs['end_date_name']]\n",
    "\n",
    "# a.infos(coacs)\n",
    "\n",
    "# For formation and dissolution\n",
    "values = '(' + ','.join([\"'CoAc\" + str(e) + \"'\" for e in coacs['pk_collective_actor'].unique()]) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_info = db.query(f\"\"\"\n",
    "    select\n",
    "        ir.fk_associated_object as pk_coac, \n",
    "        i.pk_information, \n",
    "                           i.info_label,\n",
    "        id.year, id.month, id.day,\n",
    "        id.fk_abob_type_information_date,\n",
    "        id.complement as complement, \n",
    "        id.notes as notes,\n",
    "        id.certainty_date\n",
    "    from bhp.information_role ir\n",
    "    inner join bhp.information i on i.pk_information = ir.fk_information and i.fk_type_information = 30\n",
    "    inner join bhp.information_date id on id.fk_information = i.pk_information\n",
    "    where ir.fk_associated_object in {values}\n",
    "\"\"\")\n",
    "\n",
    "formations_info['pk_coac'] = formations_info['pk_coac'].str.replace('CoAc', '', regex=False)\n",
    "formations_info['pk_coac'] = formations_info['pk_coac'].astype(pd.Int64Dtype())\n",
    "formations_info['year'] = formations_info['year'].astype(pd.Int64Dtype())\n",
    "formations_info['month'] = formations_info['month'].astype(pd.Int64Dtype())\n",
    "formations_info['day'] = formations_info['day'].astype(pd.Int64Dtype())\n",
    "formations_info['fk_abob_type_information_date'] = formations_info['fk_abob_type_information_date'].astype(pd.Int64Dtype())\n",
    "formations_info['date_bhp'] = [(row.year, row.month, row.day) for i, row in formations_info.iterrows()]\n",
    "formations_info['uri'] = ['http://symogih.org/resource/Info' + str(fk_info) for fk_info in formations_info['pk_information']]\n",
    "formations_info.drop(columns=['year', 'month', 'day', 'pk_information'], inplace=True)\n",
    "formations_info['complement'] = [pd.NA if pd.isna(row['complement']) or row['complement'].strip() == '' else row['complement'] for _,row in formations_info.iterrows()]\n",
    "formations_info['notes'] = [pd.NA if pd.isna(row['notes']) or row['notes'].strip() == '' else row['notes'] for _,row in formations_info.iterrows()]\n",
    "formations_info['notes'] = [s.replace('<p>', '').replace('</p>', '') if pd.notna(s) else pd.NA for s in formations_info['notes']]\n",
    "formations_info['notes'] = [s.replace('<em>', '').replace('</em>', '') if pd.notna(s) else pd.NA for s in formations_info['notes']]\n",
    "formations_info['complement'] = [e.replace('<p>', '').replace('</p>', '') if pd.notna(e) else pd.NA for e in formations_info['complement']]\n",
    "\n",
    "# a.infos(formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissolutions_info = db.query(f\"\"\"\n",
    "    select\n",
    "        ir.fk_associated_object as pk_coac, \n",
    "        i.pk_information, \n",
    "        id.year, id.month, id.day,\n",
    "        id.fk_abob_type_information_date,\n",
    "        id.complement as complement, \n",
    "        id.notes as notes,\n",
    "        id.certainty_date\n",
    "    from bhp.information_role ir\n",
    "    inner join bhp.information i on i.pk_information = ir.fk_information and i.fk_type_information = 33\n",
    "    inner join bhp.information_date id on id.fk_information = i.pk_information\n",
    "    where ir.fk_associated_object in {values}\n",
    "\"\"\")\n",
    "\n",
    "dissolutions_info['pk_coac'] = dissolutions_info['pk_coac'].str.replace('CoAc', '', regex=False)\n",
    "dissolutions_info['pk_coac'] = dissolutions_info['pk_coac'].astype(pd.Int64Dtype())\n",
    "dissolutions_info['year'] = dissolutions_info['year'].astype(pd.Int64Dtype())\n",
    "dissolutions_info['month'] = dissolutions_info['month'].astype(pd.Int64Dtype())\n",
    "dissolutions_info['day'] = dissolutions_info['day'].astype(pd.Int64Dtype())\n",
    "dissolutions_info['fk_abob_type_information_date'] = dissolutions_info['fk_abob_type_information_date'].astype(pd.Int64Dtype())\n",
    "dissolutions_info['date_bhp'] = [(row.year, row.month, row.day) for i, row in dissolutions_info.iterrows()]\n",
    "dissolutions_info['uri'] = ['http://symogih.org/resource/Info' + str(fk_info) for fk_info in dissolutions_info['pk_information']]\n",
    "dissolutions_info.drop(columns=['year', 'month', 'day', 'pk_information'], inplace=True)\n",
    "dissolutions_info['complement'] = [pd.NA if pd.isna(row['complement']) or row['complement'].strip() == '' else row['complement'] for _,row in dissolutions_info.iterrows()]\n",
    "dissolutions_info['notes'] = [pd.NA if pd.isna(row['notes']) or row['notes'].strip() == '' else row['notes'] for _,row in dissolutions_info.iterrows()]\n",
    "dissolutions_info['complement'] = [e.replace('<p>', '').replace('</p>', '') if pd.notna(e) else pd.NA for e in dissolutions_info['complement']]\n",
    "\n",
    "# a.infos(dissolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Database correctly disconnected.\n"
     ]
    }
   ],
   "source": [
    "db.disconnect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GV infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Requests will not be executed\n",
      "[DB] Connecting to PRODUCTION Database ... Connected!\n",
      "[DB] Database correctly disconnected.\n",
      "Shape:  (7012, 2) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_gv</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648250</td>\n",
       "      <td>Großherzogtum Baden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>648267</td>\n",
       "      <td>Königreich Württemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>648267</td>\n",
       "      <td>Würtemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>648284</td>\n",
       "      <td>Kanton Aargau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>837196</td>\n",
       "      <td>ordo senatorius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pk_gv                    name\n",
       "0  648250     Großherzogtum Baden\n",
       "1  648267  Königreich Württemberg\n",
       "2  648267              Würtemberg\n",
       "3  648284           Kanton Aargau\n",
       "4  837196         ordo senatorius"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db.connect_geovistory('prod', skip_protection=True)\n",
    "\n",
    "groups = db.query(f\"\"\"\n",
    "    select\n",
    "        r.pk_entity as pk_gv,\n",
    "        a3.string as name\n",
    "    from information.resource r\n",
    "    inner join information.statement s1 on s1.fk_object_info = r.pk_entity and s1.fk_property = {pks.properties.apial_isAppelationForLanguageOf_entity}\n",
    "    inner join information.statement s2 on s2.fk_subject_info = s1.fk_subject_info and s2.fk_property = {pks.properties.aial_refersToName_appellation}\n",
    "    inner join information.appellation a3 on a3.pk_entity = s2.fk_object_info\n",
    "    where r.fk_class = {pks.classes.group}                  \n",
    "\"\"\")\n",
    "db.disconnect()\n",
    "\n",
    "a.infos(groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collective_actors = coacs[['pk_collective_actor', 'name']].rename(columns={'pk_collective_actor':'pk_bhp'})\n",
    "\n",
    "# # Prepare strings\n",
    "# collective_actors['name_compare'] = [unidecode(s.lower()) for s in collective_actors.name]\n",
    "# groups['name_compare'] = [unidecode(s.lower()) for s in groups.name]\n",
    "\n",
    "# threshold = 0.5\n",
    "\n",
    "# similars = []\n",
    "# eta.begin(len(collective_actors), 'Finding similars')\n",
    "# for i, row_bhp in collective_actors.iterrows():\n",
    "#     for j, row_gv in groups.iterrows():\n",
    "#         score = u.trigram_similarity(row_bhp['name_compare'], row_gv['name_compare'])\n",
    "#         if score >= threshold: \n",
    "#             # eta.print(f'Found, score {score}: (' + str(row_bhp['pk_bhp']) + ') <' + str(row_bhp['name']) + '> - <' + str(row_gv['name']) + '> (' + str(row_gv['pk_gv']) + ')')\n",
    "#             similars.append({\n",
    "#                 'score': score,\n",
    "#                 'pk_bhp': row_bhp['pk_bhp'],\n",
    "#                 'name_bhp': row_bhp['name'],\n",
    "#                 'name_gv': row_gv['name'],\n",
    "#                 'pk_gv': row_gv['pk_gv']\n",
    "#             })\n",
    "#     eta.iter()\n",
    "# eta.end()\n",
    "\n",
    "# similars = pd.DataFrame(data=similars)\n",
    "# similars.sort_values('score', ascending=False, inplace=True)\n",
    "# similars.drop_duplicates(['pk_bhp', 'pk_gv'], inplace=True)\n",
    "# u.save_df(similars, '../../data/record-linkage-collective-actors.csv')\n",
    "\n",
    "# a.infos(similars)\n",
    "\n",
    "# 2h22m15s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (127, 6) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>pk_bhp</th>\n",
       "      <th>Doublon</th>\n",
       "      <th>name_bhp</th>\n",
       "      <th>name_gv</th>\n",
       "      <th>pk_gv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13762</td>\n",
       "      <td>oui</td>\n",
       "      <td>Carmel de Saint-Joseph et de Sainte-Thérèse (N...</td>\n",
       "      <td>Carmel de Saint-Joseph et de Sainte-Thérèse (N...</td>\n",
       "      <td>6141350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13761</td>\n",
       "      <td>oui</td>\n",
       "      <td>Carmel de Notre-Dame des neiges (Nancy I)</td>\n",
       "      <td>Carmel de Notre-Dame des Neiges (Nancy I)</td>\n",
       "      <td>6141170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13760</td>\n",
       "      <td>oui</td>\n",
       "      <td>Carmel de Morlaix I</td>\n",
       "      <td>Carmel de Morlaix I</td>\n",
       "      <td>6141577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>oui</td>\n",
       "      <td>Ordo fratrum praedicatorum</td>\n",
       "      <td>Ordo Fratrum Prædicatorum</td>\n",
       "      <td>1859975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13756</td>\n",
       "      <td>oui</td>\n",
       "      <td>Carmel de Saint-Joseph et de Sainte-Thérèse (C...</td>\n",
       "      <td>Carmel de Saint-Joseph et de Sainte-Thérèse (C...</td>\n",
       "      <td>6140898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  pk_bhp Doublon                                           name_bhp  \\\n",
       "0    1.0   13762     oui  Carmel de Saint-Joseph et de Sainte-Thérèse (N...   \n",
       "1    1.0   13761     oui          Carmel de Notre-Dame des neiges (Nancy I)   \n",
       "2    1.0   13760     oui                                Carmel de Morlaix I   \n",
       "3    1.0      25     oui                         Ordo fratrum praedicatorum   \n",
       "4    1.0   13756     oui  Carmel de Saint-Joseph et de Sainte-Thérèse (C...   \n",
       "\n",
       "                                             name_gv    pk_gv  \n",
       "0  Carmel de Saint-Joseph et de Sainte-Thérèse (N...  6141350  \n",
       "1          Carmel de Notre-Dame des Neiges (Nancy I)  6141170  \n",
       "2                                Carmel de Morlaix I  6141577  \n",
       "3                          Ordo Fratrum Prædicatorum  1859975  \n",
       "4  Carmel de Saint-Joseph et de Sainte-Thérèse (C...  6140898  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "record_linkage = u.read_df('../../data/record-linkage-collective-actors-filled.csv', sep=',', skip_info=True)\n",
    "record_linkage = record_linkage[record_linkage['Doublon'] == \"oui\"]\n",
    "# record_linkage = record_linkage[['pk_bhp', 'pk_gv']]\n",
    "\n",
    "a.infos(record_linkage)\n",
    "not_to_create = record_linkage['pk_bhp'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>pk_bhp</th>\n",
       "      <th>Doublon</th>\n",
       "      <th>name_bhp</th>\n",
       "      <th>name_gv</th>\n",
       "      <th>pk_gv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score, pk_bhp, Doublon, name_bhp, name_gv, pk_gv]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to verify that a single bhp entity correspond at most at one gv entity\n",
    "record_linkage[record_linkage.duplicated('pk_bhp', keep=False)].sort_values('pk_bhp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Connecting to STAGING Database ... Connected!\n"
     ]
    }
   ],
   "source": [
    "db.connect_geovistory(env, pk_project, execute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 21882 resources of class [68] ... Done in [00h00'03]\n",
      "Creating info_proj_rel of 21882 entities with project <11850066> ... Done in [00h00'08]\n"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "selection = coacs[['pk_collective_actor']].drop_duplicates()\n",
    "\n",
    "# Remove those already existing (record linkage)\n",
    "selection = selection[[pk_bhp not in not_to_create for pk_bhp in selection['pk_collective_actor']]]\n",
    "\n",
    "# Create data\n",
    "selection['pk_gv'] = db.resources.create(pks.classes.group, len(selection))\n",
    "\n",
    "# Merge into dataframe - new ones\n",
    "coacs = coacs.merge(selection, on='pk_collective_actor', how='left')\n",
    "# Merge into dataframe - from record linkage\n",
    "coacs = coacs.merge(record_linkage, left_on='pk_collective_actor', right_on='pk_bhp', how='left').drop(columns=['pk_bhp'])\n",
    "\n",
    "coacs['pk_gv'] = [row['pk_gv_x'] if pd.notna(row['pk_gv_x']) else row['pk_gv_y'] for _,row in coacs.iterrows()]\n",
    "coacs['pk_gv'] = coacs['pk_gv'].astype(pd.Int64Dtype())\n",
    "coacs.drop(columns=['pk_gv_x', 'pk_gv_y'], inplace=True)\n",
    "\n",
    "# 11s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 22009 resources of class [967] ... Done in [00h00'03]\n",
      "Creating info_proj_rel of 22009 entities with project <11850066> ... Done in [00h00'08]\n",
      "Creating 22009 appellations ... Done in [00h00'19]\n",
      "Creating 22009 statements ... Updating metadata ... Done in [00h00'18]\n",
      "Creating info_proj_rel of 22009 entities with project <11850066> ... Done in [00h00'07]\n",
      "Creating 22009 statements ... Updating metadata ... Done in [00h00'16]\n",
      "Creating info_proj_rel of 22009 entities with project <11850066> ... Done in [00h00'07]\n"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "coacs['uri'] = 'http://symogih.org/resource/CoAc' + coacs['pk_collective_actor'].astype(str)\n",
    "selection = coacs[['pk_gv', 'uri']].drop_duplicates()\n",
    "\n",
    "# Create data\n",
    "db.shortcuts.add_uris(selection['pk_gv'], selection['uri'])\n",
    "\n",
    "# 1m20s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appe_type(fk_abob_type):\n",
    "    if pd.isna(fk_abob_type): return pd.NA\n",
    "    if fk_abob_type == 1253: return 1645890\n",
    "    if fk_abob_type == 1051: return 1645890 # cf discussion avec VA sur Discord\n",
    "    if fk_abob_type == 1270: return 1661195\n",
    "    if fk_abob_type == 1063: return 8067077\n",
    "    return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 23699 resources of class [365] ... Done in [00h00'03]\n",
      "Creating info_proj_rel of 23699 entities with project <11850066> ... Done in [00h00'08]\n",
      "Creating 23699 statements ... Updating metadata ... Done in [00h00'18]\n",
      "Creating info_proj_rel of 23699 entities with project <11850066> ... Done in [00h00'09]\n",
      "Creating 23699 appellations ... Done in [00h00'21]\n",
      "Creating 23699 statements ... Updating metadata ... Done in [00h00'19]\n",
      "Creating info_proj_rel of 23699 entities with project <11850066> ... Done in [00h00'08]\n",
      "Creating 10598 statements ... Updating metadata ... Done in [00h00'08]\n",
      "Creating info_proj_rel of 10598 entities with project <11850066> ... Done in [00h00'05]\n",
      "Creating 8985 statements ... Updating metadata ... Done in [00h00'08]\n",
      "Creating info_proj_rel of 8985 entities with project <11850066> ... Done in [00h00'04]\n",
      "Creating 1312 time primitives ... Done in [00h00'00]\n",
      "Creating 1312 statements ... Updating metadata ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 1312 entities with project <11850066> ... Done in [00h00'01]\n",
      "Creating 586 time primitives ... Done in [00h00'00]\n",
      "Creating 586 statements ... Updating metadata ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 586 entities with project <11850066> ... Done in [00h00'01]\n"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "selection = coacs[['pk_gv', 'name', 'lang_name', 'comment_begin_year_name', 'comment_end_year_name', 'notes_name', 'fk_abob_coac_name_type', 'begin_date_name', 'end_date_name']].drop_duplicates(['pk_gv', 'name']).copy()\n",
    "selection['pk_lang_name'] = [pks.languages.from_iso_code(lang) if pd.notna(lang) else pd.NA for lang in selection['lang_name']]\n",
    "selection['pk_aial_type'] = [get_appe_type(t) for t in selection.fk_abob_coac_name_type]\n",
    "\n",
    "# Create - AiaL\n",
    "selection['pk_aial'] = db.resources.create(pks.classes.aial, len(selection))\n",
    "db.statements.create(selection['pk_aial'], pks.properties.apial_isAppelationForLanguageOf_entity, selection['pk_gv'])\n",
    "\n",
    "# Create - Appellation\n",
    "selection['pk_appe_name'] = db.appellations.create(selection['name'])\n",
    "db.statements.create(selection['pk_aial'], pks.properties.aial_refersToName_appellation, selection['pk_appe_name'])\n",
    "\n",
    "# Create - Language\n",
    "selection_lang = selection[pd.notna(selection['pk_lang_name'])] # Because here, we have names without a language\n",
    "db.statements.create(selection_lang['pk_aial'], pks.properties.apial_usedInLanguage_language, selection_lang['pk_lang_name'])\n",
    "\n",
    "# Create - Type\n",
    "selection_type = selection[pd.notna(selection['pk_aial_type'])]\n",
    "db.statements.create(selection_type['pk_aial'], pks.properties.aial_hasType_aialType, selection_type['pk_aial_type'])\n",
    "\n",
    "# Create - Dates\n",
    "def get_duration(date):\n",
    "    if pd.notna(date[0]) and pd.isna(date[1]) and pd.isna(date[2]): return '1 year'\n",
    "    if pd.notna(date[0]) and pd.notna(date[1]) and pd.isna(date[2]): return '1 month'\n",
    "    if pd.notna(date[0]) and pd.notna(date[1]) and pd.notna(date[2]): return '1 day'\n",
    "    return pd.NA\n",
    "\n",
    "# Create - Dates - Begin\n",
    "selection_date_begin = selection[pd.notna(selection['begin_date_name'])].copy()\n",
    "selection_date_begin['duration'] = [get_duration(d) for d in selection_date_begin['begin_date_name']]\n",
    "selection_date_begin['pk_tp'] = db.time_primitives.create(selection_date_begin['begin_date_name'], selection_date_begin['duration'])\n",
    "db.statements.create(selection_date_begin['pk_aial'], pks.properties.timespan_endOfTheBegin_timePrim, selection_date_begin['pk_tp'])\n",
    "\n",
    "# Create - Dates - End\n",
    "selection_date_end = selection[pd.notna(selection['end_date_name'])].copy()\n",
    "selection_date_end['duration'] = [get_duration(d) for d in selection_date_end['end_date_name']]\n",
    "selection_date_end['pk_tp'] = db.time_primitives.create(selection_date_end['end_date_name'], selection_date_end['duration'])\n",
    "db.statements.create(selection_date_end['pk_aial'], pks.properties.timespan_endOfTheEnd_timePrim, selection_date_end['pk_tp'])\n",
    "\n",
    "# 2m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 17516 resources of class [899] ... Done in [00h00'02]\n",
      "Creating info_proj_rel of 17516 entities with project <11850066> ... Done in [00h00'06]\n",
      "Creating 17516 appellations ... Done in [00h16'16]\n",
      "Creating 17516 statements ... Updating metadata ... Done in [00h00'13]\n",
      "Creating info_proj_rel of 17516 entities with project <11850066> ... Done in [00h00'08]\n",
      "Creating 17516 statements ... Updating metadata ... Done in [00h00'15]\n",
      "Creating info_proj_rel of 17516 entities with project <11850066> ... Done in [00h00'05]\n",
      "Creating 17516 statements ... Updating metadata ... Done in [00h00'15]\n",
      "Creating info_proj_rel of 17516 entities with project <11850066> ... Done in [00h00'05]\n"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "selection = coacs[['pk_gv', 'notes_coac', 'text', 'property_type', 'lang_text_prop']].copy().drop_duplicates()\n",
    "selection = selection[pd.notna(selection['notes_coac']) | pd.notna(selection['text'])]\n",
    "selection = selection[selection['notes_coac'].astype(str) != selection['text'].astype(str)]\n",
    "selection['note'] = ['[Note] ' + s if pd.notna(s) else pd.NA for s in selection['notes_coac']]\n",
    "selection['lang_note'] = 'fra'\n",
    "selection['text_prop'] = ['[Complément] ' + str(row['text']) if pd.notna(row['property_type']) and row['property_type'] == 'complément' else row['text'] for _,row in selection.iterrows()]\n",
    "selection['lang_text_prop'] = [pd.NA if pd.notna(d) and d == 'None' else d for d in selection['lang_text_prop']]\n",
    "\n",
    "definitions = pd.concat([\n",
    "    selection[['pk_gv', 'note', 'lang_note']].dropna(subset='note').rename(columns={'note':'definition', 'lang_note':'lang'}), \n",
    "    selection[['pk_gv', 'text_prop', 'lang_text_prop']].dropna(subset='text_prop').rename(columns={'text_prop':'definition', 'lang_text_prop':'lang'})\n",
    "])\n",
    "definitions['lang'].fillna('fra', inplace=True)\n",
    "definitions['pk_lang'] = [pks.languages.from_iso_code(c) for c in definitions['lang']]\n",
    "\n",
    "# Create data\n",
    "db.shortcuts.add_definitions(definitions['pk_gv'].tolist(), definitions['definition'].tolist(), definitions['pk_lang'].tolist())\n",
    "\n",
    "# 17m30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation = coacs[['pk_gv', 'pk_collective_actor', 'begin_year_coac', 'certainty_begin', 'notes_begin']]\n",
    "formation = formation.merge(formations_info, left_on='pk_collective_actor', right_on='pk_coac', how='left').drop(columns=['pk_coac'])\n",
    "\n",
    "# Date\n",
    "formation['date'] = [row['date_bhp'] if pd.notna(row['date_bhp']) else ((row['begin_year_coac'], pd.NA, pd.NA) if pd.notna(row['begin_year_coac']) else pd.NA) for _,row in formation.iterrows()]\n",
    "formation.drop(columns=['date_bhp', 'begin_year_coac'], inplace=True)\n",
    "\n",
    "# Property\n",
    "def get_property(note_begin, fk_type):\n",
    "    if pd.notna(fk_type):\n",
    "        if fk_type == 246: return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive # P82\n",
    "        if fk_type == 1125: return pks.properties.timespan_beginOfTheBegin_timePrim # P82a\n",
    "        if fk_type == 1126: return pks.properties.timespan_endOfTheEnd_timePrim # P82b\n",
    "        if fk_type == 258: return pks.properties.timeSpan_ongoingThroughout_timePrimitive #P81\n",
    "        if fk_type == 1289: return pks.properties.timespan_endOfTheBegin_timePrim # P81a\n",
    "        if fk_type == 1290: return pks.properties.timespan_beginOfTheEnd_timePrim # P81b\n",
    "        if fk_type == 1321: return pks.properties.timespan_beginOfTheBegin_timePrim\n",
    "        if fk_type == 1322: return pks.properties.timespan_beginOfTheBegin_timePrim\n",
    "        if fk_type == 1323: return pks.properties.timespan_endOfTheBegin_timePrim\n",
    "        if fk_type == 256: return pks.properties.timespan_endOfTheEnd_timePrim\n",
    "        if fk_type == 1127: return pks.properties.timespan_beginOfTheEnd_timePrim\n",
    "        if fk_type == 1128: return pks.properties.timespan_endOfTheEnd_timePrim\n",
    "        return pd.NA\n",
    "    elif pd.notna(note_begin):\n",
    "        if note_begin == 1: return pks.properties.timespan_endOfTheBegin_timePrim\n",
    "        if note_begin == 2: return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive\n",
    "        if note_begin == 3: return pks.properties.timeSpan_ongoingThroughout_timePrimitive\n",
    "        if note_begin == 4: return pks.properties.timespan_beginOfTheEnd_timePrim\n",
    "        return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive\n",
    "    else: return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive\n",
    "formation['pk_property'] = [get_property(row['notes_begin'], row['fk_abob_type_information_date']) for _,row in formation.iterrows()]\n",
    "formation.drop(columns=['fk_abob_type_information_date', 'notes_begin'], inplace=True)\n",
    "\n",
    "# Certainty\n",
    "formation['certainty'] = [row['certainty_date'] if pd.notna(row['certainty_date']) else row['certainty_begin'] for _,row in formation.iterrows()]\n",
    "formation.drop(columns=['certainty_begin', 'certainty_date'], inplace=True)\n",
    "\n",
    "# Notes \n",
    "formation['notes'] = ['[Note] ' + str(e) if pd.notna(e) else pd.NA for e in formation['notes']]\n",
    "\n",
    "# 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 13717 resources of class [60] ... Done in [00h00'02]\n",
      "Creating info_proj_rel of 13717 entities with project <11850066> ... Done in [00h00'05]\n",
      "Creating 13717 statements ... Updating metadata ... Done in [00h00'11]\n",
      "Creating info_proj_rel of 13717 entities with project <11850066> ... Done in [00h00'06]\n",
      "Creating 13717 time primitives ... Done in [00h00'01]\n",
      "Creating 4518 resources of class [900] ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 4518 entities with project <11850066> ... Done in [00h00'02]\n",
      "Creating 4518 appellations ... Done in [00h00'01]\n",
      "Creating 4518 statements ... Updating metadata ... Done in [00h00'04]\n",
      "Creating info_proj_rel of 4518 entities with project <11850066> ... Done in [00h00'02]\n",
      "Creating 4518 statements ... Updating metadata ... Done in [00h00'04]\n",
      "Creating info_proj_rel of 4518 entities with project <11850066> ... Done in [00h00'02]\n",
      "Creating 9307 resources of class [967] ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 9307 entities with project <11850066> ... Done in [00h00'03]\n",
      "Creating 9307 appellations ... Done in [00h00'09]\n",
      "Creating 9307 statements ... Updating metadata ... Done in [00h00'07]\n",
      "Creating info_proj_rel of 9307 entities with project <11850066> ... Done in [00h00'05]\n",
      "Creating 9307 statements ... Updating metadata ... Done in [00h00'09]\n",
      "Creating info_proj_rel of 9307 entities with project <11850066> ... Done in [00h00'04]\n",
      "Creating 171 resources of class [900] ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 171 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 171 statements ... Updating metadata ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 171 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 171 appellations ... Done in [00h00'00]\n",
      "Creating 171 statements ... Updating metadata ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 171 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 179 resources of class [900] ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 179 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 179 statements ... Updating metadata ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 179 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 179 appellations ... Done in [00h00'01]\n",
      "Creating 179 statements ... Updating metadata ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 179 entities with project <11850066> ... Done in [00h00'00]\n"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "selection = formation[pd.notna(formation['date'])].copy()\n",
    "\n",
    "# Create Formation\n",
    "selection['pk_formation'] = db.resources.create(pks.classes.formation, len(selection))\n",
    "db.statements.create(selection['pk_formation'], pks.properties.formation_hasFormed_group, selection['pk_collective_actor'])\n",
    "\n",
    "# Link to date\n",
    "selection['duration'] = [get_duration(d) for d in selection['date']]\n",
    "selection['pk_time_prim'] = db.time_primitives.create(selection['date'], selection['duration'])\n",
    "\n",
    "# Certainty comment\n",
    "selection_certainty_comment = selection[(selection['certainty'] == 2) | (selection['certainty'] == 3)].copy()\n",
    "selection_certainty_comment['comment'] = ['Date reconstituée' if c == 2 else 'Date postulée' for c in selection_certainty_comment['certainty']]\n",
    "selection_certainty_comment['pk_certainty_comment'] = db.resources.create(pks.classes.comment, len(selection_certainty_comment))\n",
    "selection_certainty_comment['pk_appe'] = db.appellations.create(selection_certainty_comment['comment'])\n",
    "db.statements.create(selection_certainty_comment['pk_certainty_comment'], pks.properties.text_hasValueVersion_string, selection_certainty_comment['pk_appe'])\n",
    "db.statements.create(selection_certainty_comment['pk_certainty_comment'], pks.properties.comment_hasCommentType_CommentType, 7953586)\n",
    "\n",
    "# URI\n",
    "selection_uri = selection[pd.notna(selection['uri'])]\n",
    "db.shortcuts.add_uris(selection_uri['pk_formation'], selection_uri['uri'])\n",
    "\n",
    "# Compléments sur la date\n",
    "selection_cplmt_date = selection[pd.notna(selection['complement'])].copy()\n",
    "selection_cplmt_date['pk_comment'] = db.resources.create(pks.classes.comment, len(selection_cplmt_date))\n",
    "db.statements.create(selection_cplmt_date['pk_comment'], pks.properties.comment_hasCommentType_CommentType, 8065621) # Complément sur la date\n",
    "selection_cplmt_date['pk_appe'] = db.appellations.create(selection_cplmt_date['complement'])\n",
    "db.statements.create(selection_cplmt_date['pk_comment'], pks.properties.text_hasValueVersion_string, selection_cplmt_date['pk_appe'])\n",
    "\n",
    "# Notes sur la date\n",
    "selection_notes_date = selection[pd.notna(selection['notes'])].copy()\n",
    "selection_notes_date['pk_comment'] = db.resources.create(pks.classes.comment, len(selection_notes_date))\n",
    "db.statements.create(selection_notes_date['pk_comment'], pks.properties.comment_hasCommentType_CommentType, 8065632) # Notes sur la date\n",
    "selection_notes_date['pk_appe'] = db.appellations.create(selection_notes_date['notes'])\n",
    "db.statements.create(selection_notes_date['pk_comment'], pks.properties.text_hasValueVersion_string, selection_notes_date['pk_appe'])\n",
    "\n",
    "# 1m22s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dissolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissolution = coacs[['pk_gv', 'pk_collective_actor', 'end_year_coac', 'certainty_end', 'notes_end']]\n",
    "dissolution = dissolution.merge(dissolutions_info, left_on='pk_collective_actor', right_on='pk_coac', how='left').drop(columns=['pk_coac'])\n",
    "\n",
    "# Date\n",
    "dissolution['date'] = [row['date_bhp'] if pd.notna(row['date_bhp']) else ((row['end_year_coac'], pd.NA, pd.NA) if pd.notna(row['end_year_coac']) else pd.NA) for _,row in dissolution.iterrows()]\n",
    "dissolution.drop(columns=['date_bhp', 'end_year_coac'], inplace=True)\n",
    "\n",
    "# Property\n",
    "def get_property(note_end, fk_type):\n",
    "    if pd.notna(fk_type):\n",
    "        if fk_type == 246: return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive # P82\n",
    "        if fk_type == 1125: return pks.properties.timespan_beginOfTheBegin_timePrim # P82a\n",
    "        if fk_type == 1126: return pks.properties.timespan_endOfTheEnd_timePrim # P82b\n",
    "        if fk_type == 258: return pks.properties.timeSpan_ongoingThroughout_timePrimitive #P81\n",
    "        if fk_type == 1289: return pks.properties.timespan_endOfTheBegin_timePrim # P81a\n",
    "        if fk_type == 1290: return pks.properties.timespan_beginOfTheEnd_timePrim # P81b\n",
    "        if fk_type == 1321: return pks.properties.timespan_beginOfTheBegin_timePrim\n",
    "        if fk_type == 1322: return pks.properties.timespan_beginOfTheBegin_timePrim\n",
    "        if fk_type == 1323: return pks.properties.timespan_endOfTheBegin_timePrim\n",
    "        if fk_type == 256: return pks.properties.timespan_endOfTheEnd_timePrim\n",
    "        if fk_type == 1127: return pks.properties.timespan_beginOfTheEnd_timePrim\n",
    "        if fk_type == 1128: return pks.properties.timespan_endOfTheEnd_timePrim\n",
    "        return pd.NA\n",
    "    elif pd.notna(note_end):\n",
    "        if note_end == 1: return pks.properties.timespan_endOfTheBegin_timePrim\n",
    "        if note_end == 2: return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive\n",
    "        if note_end == 3: return pks.properties.timeSpan_ongoingThroughout_timePrimitive\n",
    "        if note_end == 4: return pks.properties.timespan_beginOfTheEnd_timePrim\n",
    "        return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive\n",
    "    else: return pks.properties.timeSpan_atSomeTimeWithin_timePrimitive\n",
    "dissolution['pk_property'] = [get_property(row['notes_end'], row['fk_abob_type_information_date']) for _,row in dissolution.iterrows()]\n",
    "dissolution.drop(columns=['fk_abob_type_information_date', 'notes_end'], inplace=True)\n",
    "\n",
    "# Certainty\n",
    "dissolution['certainty'] = [row['certainty_date'] if pd.notna(row['certainty_date']) else row['certainty_end'] for _,row in dissolution.iterrows()]\n",
    "dissolution.drop(columns=['certainty_end', 'certainty_date'], inplace=True)\n",
    "\n",
    "# Notes \n",
    "dissolution['notes'] = ['[Note] ' + str(e) if pd.notna(e) else pd.NA for e in dissolution['notes']]\n",
    "\n",
    "# 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_gv</th>\n",
       "      <th>pk_collective_actor</th>\n",
       "      <th>complement</th>\n",
       "      <th>notes</th>\n",
       "      <th>uri</th>\n",
       "      <th>date</th>\n",
       "      <th>pk_property</th>\n",
       "      <th>certainty</th>\n",
       "      <th>pk_dissolution</th>\n",
       "      <th>duration</th>\n",
       "      <th>pk_time_prim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18972</th>\n",
       "      <td>11460498</td>\n",
       "      <td>15408</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[Note] &lt;p&gt;Non documenté après 1935&lt;/p&gt;</td>\n",
       "      <td>http://symogih.org/resource/Info112695</td>\n",
       "      <td>(1935, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11846228</td>\n",
       "      <td>1 year</td>\n",
       "      <td>742444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18973</th>\n",
       "      <td>11460498</td>\n",
       "      <td>15408</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[Note] &lt;p&gt;Non documenté après 1935&lt;/p&gt;</td>\n",
       "      <td>http://symogih.org/resource/Info112695</td>\n",
       "      <td>(1935, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11846229</td>\n",
       "      <td>1 year</td>\n",
       "      <td>742444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pk_gv  pk_collective_actor complement  \\\n",
       "18972  11460498                15408       <NA>   \n",
       "18973  11460498                15408       <NA>   \n",
       "\n",
       "                                        notes  \\\n",
       "18972  [Note] <p>Non documenté après 1935</p>   \n",
       "18973  [Note] <p>Non documenté après 1935</p>   \n",
       "\n",
       "                                          uri                date  \\\n",
       "18972  http://symogih.org/resource/Info112695  (1935, <NA>, <NA>)   \n",
       "18973  http://symogih.org/resource/Info112695  (1935, <NA>, <NA>)   \n",
       "\n",
       "       pk_property certainty  pk_dissolution duration  pk_time_prim  \n",
       "18972           72       3.0        11846228   1 year        742444  \n",
       "18973           72       3.0        11846229   1 year        742444  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "selection_notes_date = selection[pd.notna(selection['notes'])].copy()\n",
    "selection_notes_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 7592 resources of class [62] ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 7592 entities with project <11850066> ... Done in [00h00'03]\n",
      "Creating 7592 statements ... Updating metadata ... Done in [00h00'06]\n",
      "Creating info_proj_rel of 7592 entities with project <11850066> ... Done in [00h00'03]\n",
      "Creating 7592 time primitives ... Done in [00h00'00]\n",
      "Creating 4235 resources of class [900] ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 4235 entities with project <11850066> ... Done in [00h00'01]\n",
      "Creating 4235 appellations ... Done in [00h00'02]\n",
      "Creating 4235 statements ... Updating metadata ... Done in [00h00'03]\n",
      "Creating info_proj_rel of 4235 entities with project <11850066> ... Done in [00h00'01]\n",
      "Creating 4235 statements ... Updating metadata ... Done in [00h00'04]\n",
      "Creating info_proj_rel of 4235 entities with project <11850066> ... Done in [00h00'01]\n",
      "Creating 64 resources of class [967] ... Done in [00h00'01]\n",
      "Creating info_proj_rel of 64 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 64 appellations ... Done in [00h00'00]\n",
      "Creating 64 statements ... Updating metadata ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 64 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 64 statements ... Updating metadata ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 64 entities with project <11850066> ... Done in [00h00'00]\n",
      "Creating 0 resources of class [900] ... "
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.SyntaxError) syntax error at or near \"returning\"\nLINE 4:         returning pk_entity;\n                ^\n\n[SQL: \n        insert into information.resource\n            (fk_class, community_visibility, metadata) values \n        returning pk_entity;\n    ]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mSyntaxError\u001b[0m: syntax error at or near \"returning\"\nLINE 4:         returning pk_entity;\n                ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Compléments sur la date\u001b[39;00m\n\u001b[1;32m     25\u001b[0m selection_cplmt_date \u001b[39m=\u001b[39m selection[pd\u001b[39m.\u001b[39mnotna(selection[\u001b[39m'\u001b[39m\u001b[39mcomplement\u001b[39m\u001b[39m'\u001b[39m])]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 26\u001b[0m selection_cplmt_date[\u001b[39m'\u001b[39m\u001b[39mpk_comment\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39;49mresources\u001b[39m.\u001b[39;49mcreate(pks\u001b[39m.\u001b[39;49mclasses\u001b[39m.\u001b[39;49mcomment, \u001b[39mlen\u001b[39;49m(selection_cplmt_date))\n\u001b[1;32m     27\u001b[0m db\u001b[39m.\u001b[39mstatements\u001b[39m.\u001b[39mcreate(selection_cplmt_date[\u001b[39m'\u001b[39m\u001b[39mpk_comment\u001b[39m\u001b[39m'\u001b[39m], pks\u001b[39m.\u001b[39mproperties\u001b[39m.\u001b[39mcomment_hasCommentType_CommentType, \u001b[39m8065621\u001b[39m) \u001b[39m# Complément sur la date\u001b[39;00m\n\u001b[1;32m     28\u001b[0m selection_cplmt_date[\u001b[39m'\u001b[39m\u001b[39mpk_appe\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mappellations\u001b[39m.\u001b[39mcreate(selection_cplmt_date[\u001b[39m'\u001b[39m\u001b[39mcomplement\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/geovpylib/database/resources.py:27\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(pk_class, number, metadata)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m __create_batch(pk_class, number, metadata)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mglobals\u001b[39m\u001b[39m.\u001b[39minsert_manner \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mone-shot\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mglobals\u001b[39m\u001b[39m.\u001b[39mexecute:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m __create_oneshot(pk_class, number, metadata)\n\u001b[1;32m     29\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInsert manner \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mglobals\u001b[39m\u001b[39m.\u001b[39minsert_manner\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m unknown.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/geovpylib/database/resources.py:92\u001b[0m, in \u001b[0;36m__create_oneshot\u001b[0;34m(pk_class, number, metadata, verbose)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m# Execution\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mglobals\u001b[39m\u001b[39m.\u001b[39mexecute:\n\u001b[0;32m---> 92\u001b[0m     response: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mexecute(sql, format_df\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     93\u001b[0m     pk_entities \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mpk_entity\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/geovpylib/database/tools.py:18\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(sql, format_df)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m format_df:\n\u001b[1;32m     17\u001b[0m     \u001b[39m# transaction = globals.db_connection.begin()\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(sql, \u001b[39mglobals\u001b[39;49m\u001b[39m.\u001b[39;49mdb_connection)\n\u001b[1;32m     19\u001b[0m     \u001b[39mglobals\u001b[39m\u001b[39m.\u001b[39mdb_connection\u001b[39m.\u001b[39mcommit()\n\u001b[1;32m     20\u001b[0m     \u001b[39m# transaction.close()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:663\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mread_table(\n\u001b[1;32m    654\u001b[0m         sql,\n\u001b[1;32m    655\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    661\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    664\u001b[0m         sql,\n\u001b[1;32m    665\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    666\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    667\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    668\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    669\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    670\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    671\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    672\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   1682\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1683\u001b[0m     sql: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1691\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   1692\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[39m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1736\u001b[0m \n\u001b[1;32m   1737\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1738\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[1;32m   1739\u001b[0m     columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m   1741\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1562\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   1560\u001b[0m args \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m [params]\n\u001b[1;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sql, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon\u001b[39m.\u001b[39;49mexec_driver_sql(sql, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1563\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon\u001b[39m.\u001b[39mexecute(sql, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1774\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1769\u001b[0m execution_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execution_options\u001b[39m.\u001b[39mmerge_with(\n\u001b[1;32m   1770\u001b[0m     execution_options\n\u001b[1;32m   1771\u001b[0m )\n\u001b[1;32m   1773\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m-> 1774\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1775\u001b[0m     dialect,\n\u001b[1;32m   1776\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[1;32m   1777\u001b[0m     statement,\n\u001b[1;32m   1778\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1779\u001b[0m     execution_options,\n\u001b[1;32m   1780\u001b[0m     statement,\n\u001b[1;32m   1781\u001b[0m     distilled_parameters,\n\u001b[1;32m   1782\u001b[0m )\n\u001b[1;32m   1784\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1840\u001b[0m         dialect,\n\u001b[1;32m   1841\u001b[0m         context,\n\u001b[1;32m   1842\u001b[0m     )\n\u001b[1;32m   1843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1845\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1846\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1984\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1985\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2338\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2339\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1971\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1972\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1977\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.SyntaxError) syntax error at or near \"returning\"\nLINE 4:         returning pk_entity;\n                ^\n\n[SQL: \n        insert into information.resource\n            (fk_class, community_visibility, metadata) values \n        returning pk_entity;\n    ]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "selection = dissolution[pd.notna(dissolution['date'])].copy()\n",
    "\n",
    "# Create dissolution\n",
    "selection['pk_dissolution'] = db.resources.create(pks.classes.dissolution, len(selection))\n",
    "db.statements.create(selection['pk_dissolution'], pks.properties.dissolution_dissolved_group, selection['pk_collective_actor'])\n",
    "\n",
    "# Link to date\n",
    "selection['duration'] = [get_duration(d) for d in selection['date']]\n",
    "selection['pk_time_prim'] = db.time_primitives.create(selection['date'], selection['duration'])\n",
    "\n",
    "# Certainty comment\n",
    "selection_certainty_comment = selection[(selection['certainty'] == 2) | (selection['certainty'] == 3)].copy()\n",
    "selection_certainty_comment['comment'] = ['Date reconstituée' if c == 2 else 'Date postulée' for c in selection_certainty_comment['certainty']]\n",
    "selection_certainty_comment['pk_certainty_comment'] = db.resources.create(pks.classes.comment, len(selection_certainty_comment))\n",
    "selection_certainty_comment['pk_appe'] = db.appellations.create(selection_certainty_comment['comment'])\n",
    "db.statements.create(selection_certainty_comment['pk_certainty_comment'], pks.properties.text_hasValueVersion_string, selection_certainty_comment['pk_appe'])\n",
    "db.statements.create(selection_certainty_comment['pk_certainty_comment'], pks.properties.comment_hasCommentType_CommentType, 7953586)\n",
    "\n",
    "# URI\n",
    "selection_uri = selection[pd.notna(selection['uri'])]\n",
    "db.shortcuts.add_uris(selection_uri['pk_dissolution'], selection_uri['uri'])\n",
    "\n",
    "# Compléments sur la date\n",
    "selection_cplmt_date = selection[pd.notna(selection['complement'])].copy()\n",
    "selection_cplmt_date['pk_comment'] = db.resources.create(pks.classes.comment, len(selection_cplmt_date))\n",
    "db.statements.create(selection_cplmt_date['pk_comment'], pks.properties.comment_hasCommentType_CommentType, 8065621) # Complément sur la date\n",
    "selection_cplmt_date['pk_appe'] = db.appellations.create(selection_cplmt_date['complement'])\n",
    "db.statements.create(selection_cplmt_date['pk_comment'], pks.properties.text_hasValueVersion_string, selection_cplmt_date['pk_appe'])\n",
    "\n",
    "# Notes sur la date\n",
    "selection_notes_date = selection[pd.notna(selection['notes'])].copy()\n",
    "selection_notes_date['pk_comment'] = db.resources.create(pks.classes.comment, len(selection_notes_date))\n",
    "db.statements.create(selection_notes_date['pk_comment'], pks.properties.comment_hasCommentType_CommentType, 8065632) # Notes sur la date\n",
    "selection_notes_date['pk_appe'] = db.appellations.create(selection_notes_date['notes'])\n",
    "db.statements.create(selection_notes_date['pk_comment'], pks.properties.text_hasValueVersion_string, selection_notes_date['pk_appe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_gv</th>\n",
       "      <th>pk_collective_actor</th>\n",
       "      <th>info_label</th>\n",
       "      <th>complement</th>\n",
       "      <th>notes</th>\n",
       "      <th>uri</th>\n",
       "      <th>date</th>\n",
       "      <th>pk_property</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11443005</td>\n",
       "      <td>14725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1969, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11443006</td>\n",
       "      <td>9712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1945, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11443007</td>\n",
       "      <td>13649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11443007</td>\n",
       "      <td>13649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11443007</td>\n",
       "      <td>13649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25044</th>\n",
       "      <td>11464886</td>\n",
       "      <td>14385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1904, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25045</th>\n",
       "      <td>11464886</td>\n",
       "      <td>14385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1904, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25046</th>\n",
       "      <td>11464886</td>\n",
       "      <td>14385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1904, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25047</th>\n",
       "      <td>11464886</td>\n",
       "      <td>14385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1904, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25048</th>\n",
       "      <td>11464886</td>\n",
       "      <td>14385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1904, &lt;NA&gt;, &lt;NA&gt;)</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25049 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pk_gv  pk_collective_actor info_label complement notes  uri  \\\n",
       "0      11443005                14725        NaN        NaN   NaN  NaN   \n",
       "1      11443006                 9712        NaN        NaN   NaN  NaN   \n",
       "2      11443007                13649        NaN        NaN   NaN  NaN   \n",
       "3      11443007                13649        NaN        NaN   NaN  NaN   \n",
       "4      11443007                13649        NaN        NaN   NaN  NaN   \n",
       "...         ...                  ...        ...        ...   ...  ...   \n",
       "25044  11464886                14385        NaN        NaN   NaN  NaN   \n",
       "25045  11464886                14385        NaN        NaN   NaN  NaN   \n",
       "25046  11464886                14385        NaN        NaN   NaN  NaN   \n",
       "25047  11464886                14385        NaN        NaN   NaN  NaN   \n",
       "25048  11464886                14385        NaN        NaN   NaN  NaN   \n",
       "\n",
       "                     date  pk_property certainty  \n",
       "0      (1969, <NA>, <NA>)           72         1  \n",
       "1      (1945, <NA>, <NA>)           72         1  \n",
       "2                    <NA>           72         1  \n",
       "3                    <NA>           72         1  \n",
       "4                    <NA>           72         1  \n",
       "...                   ...          ...       ...  \n",
       "25044  (1904, <NA>, <NA>)           72         1  \n",
       "25045  (1904, <NA>, <NA>)           72         1  \n",
       "25046  (1904, <NA>, <NA>)           72         1  \n",
       "25047  (1904, <NA>, <NA>)           72         1  \n",
       "25048  (1904, <NA>, <NA>)           72         1  \n",
       "\n",
       "[25049 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
