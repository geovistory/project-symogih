{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[DB] Requests will not be executed\n",
      "[DB] Connecting to PRODUCTION Database ... Connected!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "env = 'prod'\n",
    "pk_project = -1\n",
    "execute = False\n",
    "metadata_str = ''\n",
    "import_manner = 'one-shot' # 'batch'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "import plotly.express as px\n",
    "\n",
    "import geovpylib.analysis as a\n",
    "import geovpylib.database as db\n",
    "import geovpylib.queries as q\n",
    "import geovpylib.pks as pks\n",
    "import geovpylib.sparql as sparql\n",
    "import geovpylib.utils as u\n",
    "\n",
    "eta = u.Eta()\n",
    "\n",
    "# db.connect_external(os.getenv(''))\n",
    "db.connect_geovistory(env, pk_project, execute)\n",
    "db.set_metadata({'import-id': datetime.today().strftime('%Y%m%d') + '-' + metadata_str})\n",
    "db.set_insert_manner(import_manner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Geographical place"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List record linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (453, 2) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_bhp</th>\n",
       "      <th>pk_gv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>205134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6201188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2220550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1485424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1876219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_bhp    pk_gv\n",
       "0       1   205134\n",
       "1       3  6201188\n",
       "2       7  2220550\n",
       "3      13  1485424\n",
       "4      19  1876219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "record_linkage = pd.read_csv('../../data/record-linkage-bhp-named-place-geov-geo-places-filled.csv')\n",
    "record_linkage = record_linkage[record_linkage['doublon'] == 'oui']\n",
    "record_linkage = record_linkage[['pk_bhp', 'pk_gv']].drop_duplicates()\n",
    "\n",
    "a.infos(record_linkage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch all bhp named places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (132681, 20) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_bhp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>abob_type_geo_place</th>\n",
       "      <th>notes_geo_place</th>\n",
       "      <th>begin_year</th>\n",
       "      <th>notes_begin</th>\n",
       "      <th>end_year</th>\n",
       "      <th>notes_end</th>\n",
       "      <th>name</th>\n",
       "      <th>lang_name</th>\n",
       "      <th>abob_type</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>comment_begin_year</th>\n",
       "      <th>end_date</th>\n",
       "      <th>comment_end_year</th>\n",
       "      <th>notes</th>\n",
       "      <th>text</th>\n",
       "      <th>lang_text_prop</th>\n",
       "      <th>type_text_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15922</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>697</td>\n",
       "      <td>Commune existante au 1er janvier 2009. Importé...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Vèbre</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nom officiel au 1er janvier 2009. Importé à pa...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15923</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>697</td>\n",
       "      <td>Commune existante au 1er janvier 2009. Importé...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Ventenac</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nom officiel au 1er janvier 2009. Importé à pa...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15924</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>697</td>\n",
       "      <td>Commune existante au 1er janvier 2009. Importé...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Verdun</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nom officiel au 1er janvier 2009. Importé à pa...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15925</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>697</td>\n",
       "      <td>Commune existante au 1er janvier 2009. Importé...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Vernajoul</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nom officiel au 1er janvier 2009. Importé à pa...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15926</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>697</td>\n",
       "      <td>Commune existante au 1er janvier 2009. Importé...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Vernaux</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nom officiel au 1er janvier 2009. Importé à pa...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_bhp   lat   lng  abob_type_geo_place  \\\n",
       "0   15922  <NA>  <NA>                  697   \n",
       "1   15923  <NA>  <NA>                  697   \n",
       "2   15924  <NA>  <NA>                  697   \n",
       "3   15925  <NA>  <NA>                  697   \n",
       "4   15926  <NA>  <NA>                  697   \n",
       "\n",
       "                                     notes_geo_place  begin_year  notes_begin  \\\n",
       "0  Commune existante au 1er janvier 2009. Importé...        <NA>         <NA>   \n",
       "1  Commune existante au 1er janvier 2009. Importé...        <NA>         <NA>   \n",
       "2  Commune existante au 1er janvier 2009. Importé...        <NA>         <NA>   \n",
       "3  Commune existante au 1er janvier 2009. Importé...        <NA>         <NA>   \n",
       "4  Commune existante au 1er janvier 2009. Importé...        <NA>         <NA>   \n",
       "\n",
       "   end_year  notes_end       name lang_name  abob_type begin_date  \\\n",
       "0      <NA>       <NA>      Vèbre      <NA>       <NA>       <NA>   \n",
       "1      <NA>       <NA>   Ventenac      <NA>       <NA>       <NA>   \n",
       "2      <NA>       <NA>     Verdun      <NA>       <NA>       <NA>   \n",
       "3      <NA>       <NA>  Vernajoul      <NA>       <NA>       <NA>   \n",
       "4      <NA>       <NA>    Vernaux      <NA>       <NA>       <NA>   \n",
       "\n",
       "  comment_begin_year end_date comment_end_year  \\\n",
       "0               <NA>     <NA>             <NA>   \n",
       "1               <NA>     <NA>             <NA>   \n",
       "2               <NA>     <NA>             <NA>   \n",
       "3               <NA>     <NA>             <NA>   \n",
       "4               <NA>     <NA>             <NA>   \n",
       "\n",
       "                                               notes  text lang_text_prop  \\\n",
       "0  Nom officiel au 1er janvier 2009. Importé à pa...  <NA>           <NA>   \n",
       "1  Nom officiel au 1er janvier 2009. Importé à pa...  <NA>           <NA>   \n",
       "2  Nom officiel au 1er janvier 2009. Importé à pa...  <NA>           <NA>   \n",
       "3  Nom officiel au 1er janvier 2009. Importé à pa...  <NA>           <NA>   \n",
       "4  Nom officiel au 1er janvier 2009. Importé à pa...  <NA>           <NA>   \n",
       "\n",
       "  type_text_prop  \n",
       "0           <NA>  \n",
       "1           <NA>  \n",
       "2           <NA>  \n",
       "3           <NA>  \n",
       "4           <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Geo place + presence + definitions? + Comment?\n",
    "named_places = u.read_df('../../data/bhp/named_place.csv', skip_info=True)\n",
    "named_places = named_places[['pk_named_place', 'standard_latitude', 'standard_longitude', 'fk_abob_type_napl', 'notes', 'begin_year', 'notes_begin', 'end_year', 'notes_end']]\n",
    "named_places.rename(columns={'pk_named_place':'pk_bhp','standard_latitude':'lat','standard_longitude':'lng','fk_abob_type_napl':'abob_type_geo_place', 'notes':'notes_geo_place'}, inplace=True)\n",
    "\n",
    "# AIAL\n",
    "named_places_names = u.read_df('../../data/bhp/named_place_name.csv', skip_info=True)\n",
    "named_places_names = named_places_names[['fk_named_place', 'name','lang_iso','fk_abob_napl_name_type','begin_date', 'comment_begin_year', 'end_date', 'comment_end_year', 'notes']]\n",
    "named_places_names.rename(columns={'fk_named_place':'pk_bhp','lang_iso':'lang_name','fk_abob_napl_name_type':'abob_type','fk_abob_type_napl':'abob_type'}, inplace=True)\n",
    "\n",
    "# Text properties\n",
    "named_places_text_prop = u.read_df('../../data/bhp/named_place_text_property.csv', skip_info=True)\n",
    "named_places_text_prop = named_places_text_prop[['fk_named_place','text','lang_iso_code','property_type']]\n",
    "named_places_text_prop.rename(columns={'fk_named_place':'pk_bhp','lang_iso_code':'lang_text_prop','property_type':'type_text_prop'}, inplace=True)\n",
    "\n",
    "\n",
    "# Merge\n",
    "named_places = named_places.merge(named_places_names, on='pk_bhp', how='left')\n",
    "named_places = named_places.merge(named_places_text_prop, on='pk_bhp', how='left')\n",
    "\n",
    "\n",
    "a.infos(named_places)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_places['pk_kind'] = pd.NA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = named_places.merge(record_linkage, on='pk_bhp', how='left')\n",
    "a.set_types(table, {'pk_gv':'int'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Geographical places in Geovistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Requests will not be executed\n",
      "[DB] Connecting to STAGING Database ... Connected!\n",
      "[DB] Database correctly disconnected.\n",
      "Shape:  (437, 5) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_gv</th>\n",
       "      <th>names</th>\n",
       "      <th>uris</th>\n",
       "      <th>presences</th>\n",
       "      <th>defs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25494</td>\n",
       "      <td>Zurich;Zürich;Zürich CH</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>47.366667 8.55</td>\n",
       "      <td>Publikationsort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25540</td>\n",
       "      <td>Arezzo</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>43.473333 11.87</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25639</td>\n",
       "      <td>Leningrad;Sankt Peterburg;Sankt Petersburg</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25685</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0 3.0;47.9990077 7.8421043</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25721</td>\n",
       "      <td>Muri</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>47.28 8.34;47.283333 8.35</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_gv                                       names  uris  \\\n",
       "0  25494                     Zurich;Zürich;Zürich CH  <NA>   \n",
       "1  25540                                      Arezzo  <NA>   \n",
       "2  25639  Leningrad;Sankt Peterburg;Sankt Petersburg  <NA>   \n",
       "3  25685                                    Freiburg  <NA>   \n",
       "4  25721                                        Muri  <NA>   \n",
       "\n",
       "                      presences             defs  \n",
       "0                47.366667 8.55  Publikationsort  \n",
       "1               43.473333 11.87                   \n",
       "2                                                 \n",
       "3  3.0 3.0;47.9990077 7.8421043                   \n",
       "4     47.28 8.34;47.283333 8.35                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db.connect_geovistory(env, -1, False, True)\n",
    "\n",
    "pk_gv = table['pk_gv'].dropna().unique()\n",
    "values = '(' + ','.join([str(e) for e in pk_gv]) + ')'\n",
    "\n",
    "existing_names = db.query(f\"\"\"\n",
    "    select distinct\n",
    "        r.pk_entity as pk_gv, a3.string as name\n",
    "    from information.resource r\n",
    "    inner join information.statement s1 on s1.fk_object_info = r.pk_entity and s1.fk_property = {pks.properties.apial_isAppelationForLanguageOf_entity}\n",
    "    inner join projects.info_proj_rel ipr1 on ipr1.fk_entity = s1.pk_entity and ipr1.is_in_project = true\n",
    "    inner join information.statement s2 on s2.fk_subject_info = s1.fk_subject_info and s2.fk_property = {pks.properties.aial_refersToName_appellation}\n",
    "    inner join projects.info_proj_rel ipr2 on ipr2.fk_entity = s2.pk_entity and ipr2.is_in_project = true\n",
    "    inner join information.appellation a3 on a3.pk_entity = s2.fk_object_info\n",
    "    where r.pk_entity in {values}                          \n",
    "\"\"\")\n",
    "\n",
    "existing_uris = db.query(f\"\"\"\n",
    "    select distinct\n",
    "        r.pk_entity as pk_gv, a6.string as uri\n",
    "    from information.resource r\n",
    "    inner join information.statement s4 on s4.fk_subject_info = r.pk_entity and s4.fk_property = {pks.properties.entity_sameAsURI_URI}\n",
    "    inner join projects.info_proj_rel ipr4 on ipr4.fk_entity = s4.pk_entity and ipr4.is_in_project = true\n",
    "    inner join information.statement s5 on s5.fk_subject_info = s4.fk_object_info and s5.fk_property = {pks.properties.appe_hasValue_string}\n",
    "    inner join projects.info_proj_rel ipr5 on ipr5.fk_entity = s5.pk_entity and ipr5.is_in_project = true\n",
    "    inner join information.appellation a6 on a6.pk_entity = s5.fk_object_info\n",
    "    where r.pk_entity in {values}\n",
    "\"\"\")\n",
    "\n",
    "existing_presence = db.query(f\"\"\"\n",
    "    select distinct\n",
    "        r.pk_entity as pk_gv, st_y(p9.geo_point::geometry) as lat, st_x(p9.geo_point::geometry) as lng\n",
    "    from information.resource r\n",
    "    inner join information.statement s7 on s7.fk_object_info = r.pk_entity and s7.fk_property = {pks.properties.presence_wasPresenceOf_spacetimeVolume}\n",
    "    inner join projects.info_proj_rel ipr7 on ipr7.fk_entity = s7.pk_entity and ipr7.is_in_project = true\n",
    "    inner join information.statement s8 on s8.fk_subject_info = s7.fk_subject_info and s8.fk_property = {pks.properties.presence_wasAt_place}\n",
    "    inner join projects.info_proj_rel ipr8 on ipr8.fk_entity = s8.pk_entity and ipr8.is_in_project = true\n",
    "    inner join information.v_place p9 on p9.pk_entity = s8.fk_object_info\n",
    "    where r.pk_entity in {values}\n",
    "\"\"\")\n",
    "existing_presence['presence'] = [str(row['lat']) + ' ' + str(row['lng']) if pd.notna(row['lat']) or pd.notna(row['lng']) else pd.NA for i,row in existing_presence.iterrows()]\n",
    "existing_presence.drop(columns=['lat', 'lng'], inplace=True)\n",
    "\n",
    "existing_def = db.query(f\"\"\"\n",
    "    select distinct\n",
    "        r.pk_entity as pk_gv, a3.string as definition\n",
    "    from information.resource r\n",
    "    inner join information.statement s1 on s1.fk_subject_info = r.pk_entity and s1.fk_property = {pks.properties.entity_hasDefinition_text}\n",
    "    inner join projects.info_proj_rel ipr1 on ipr1.fk_entity = s1.pk_entity and ipr1.is_in_project = true\n",
    "    inner join information.statement s2 on s2.fk_subject_info = s1.fk_object_info and s2.fk_property = {pks.properties.text_hasValueVersion_string}\n",
    "    inner join projects.info_proj_rel ipr2 on ipr2.fk_entity = s2.pk_entity and ipr2.is_in_project = true\n",
    "    inner join information.appellation a3 on a3.pk_entity = s2.fk_object_info\n",
    "    where r.pk_entity in {values}    \n",
    "\"\"\")\n",
    "\n",
    "db.disconnect()\n",
    "\n",
    "existing_gv = table[['pk_gv']].dropna().drop_duplicates().copy()\n",
    "existing_gv = existing_gv.merge(existing_names, how='left')\n",
    "existing_gv = existing_gv.merge(existing_uris, how='left')\n",
    "existing_gv = existing_gv.merge(existing_presence, how='left')\n",
    "existing_gv = existing_gv.merge(existing_def, how='left')\n",
    "\n",
    "existing_gv.sort_values('pk_gv', inplace=True)\n",
    "existing_gv['uri'].fillna('', inplace=True)\n",
    "existing_gv['name'].fillna('', inplace=True)\n",
    "existing_gv['definition'].fillna('', inplace=True)\n",
    "existing_gv['presence'].fillna('', inplace=True)\n",
    "\n",
    "existing_gv = existing_gv.groupby('pk_gv').agg(\n",
    "    names=pd.NamedAgg(column='name', aggfunc=lambda n: ';'.join(e for e in np.unique(n))),\n",
    "    uris=pd.NamedAgg(column='uri', aggfunc=lambda n: ';'.join(e for e in np.unique(n))),\n",
    "    presences=pd.NamedAgg(column='presence', aggfunc=lambda n: ';'.join(str(e) for e in np.unique(n))),\n",
    "    defs=pd.NamedAgg(column='definition', aggfunc=lambda n: ';;'.join(e for e in np.unique(n)))\n",
    ")\n",
    "existing_gv.reset_index(inplace=True)\n",
    "existing_gv['uris'] = existing_gv['uris'].replace('', pd.NA)\n",
    "\n",
    "a.infos(existing_gv)\n",
    "\n",
    "# 13s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geo place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = table[['pk_gv', 'pk_bhp']].drop_duplicates('pk_bhp')\n",
    "selection = selection[pd.isna(selection['pk_gv'])].copy()\n",
    "\n",
    "selection['pk_gv'] = db.resources.create(pks.classes.geoPlace, len(selection))\n",
    "\n",
    "table = table.merge(selection, on='pk_bhp', how='left')\n",
    "table['pk_gv'] = [row['pk_gv_x'] if pd.notna(row['pk_gv_x']) else row['pk_gv_left'] for _,row in table.iterrows()]\n",
    "table.drop(columns=['pk_gv_x', 'pk_gv_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: all geo places has been created?\n",
    "assert len(table[pd.isna(table['pk_gv'])]) == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geo place Kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we do not need to worry if the geo place already has a kind or not: v_statement handles it\n",
    "\n",
    "selection = table[['pk_gv', 'pk_kind']].dropna('kind')\n",
    "db.statements.create(selection['pk_gv'], pks.properties., selection['pk_kind']) # HAS KIND"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = table[pd.notna(table['lat'])]\n",
    "\n",
    "# Case 1: on geovistory, there is no presence ==> create a new presence\n",
    "# Case 2: on geovistory, there are presences but none fit the coordinates ==> create a new presence\n",
    "# Case 4: on geovistory, we found an existing presence which fit the BHP one. ==> Just add the presence to the project\n",
    "existing = selection.merge(existing_gv)\n",
    "existing['new_presence'] = existing['lat'].astype(str) + ' ' + existing['lng'].astype(str)\n",
    "existing_presence = existing[[row['new_presence'] in row['presences'] for _,row in existing.iterrows()]].drop_duplicates(['pk_bhp', 'pk_gv'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
