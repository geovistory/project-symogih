{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize already existing persons in Geovistory from the BHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import toolkit as tk\n",
    "\n",
    "from splink.duckdb.duckdb_linker import DuckDBLinker\n",
    "from splink.charts import waterfall_chart\n",
    "import splink.duckdb.duckdb_comparison_library as cl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to load Geovistory's data on one side, and BHP's data on the other, the goal being of identifing exiting persons of the BHP into Geovistory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geovistory's persons:\n",
      "Shape:  (147644, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pk</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>death_year</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>312220</td>\n",
       "      <td>bernoulli geb. baer elisabeth</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1796</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>geov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>312221</td>\n",
       "      <td>weiss ursula</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1800</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>geov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>312222</td>\n",
       "      <td>fenner hermann robert</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1859</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>geov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>312223</td>\n",
       "      <td>middleton sophia</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1813</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>geov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>312224</td>\n",
       "      <td>weil anna</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1836</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>geov</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      pk                           name gender  birth_year  \\\n",
       "0      0  312220  bernoulli geb. baer elisabeth   <NA>        1796   \n",
       "1      1  312221                   weiss ursula   <NA>        1800   \n",
       "2      2  312222          fenner hermann robert   <NA>        1859   \n",
       "3      3  312223               middleton sophia   <NA>        1813   \n",
       "4      4  312224                      weil anna   <NA>        1836   \n",
       "\n",
       "   death_year dataset  \n",
       "0        <NA>    geov  \n",
       "1        <NA>    geov  \n",
       "2        <NA>    geov  \n",
       "3        <NA>    geov  \n",
       "4        <NA>    geov  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "persons_geov = pd.read_csv('../../data/prepared_persons-geov.csv', sep=';')\n",
    "tk.set_types(persons_geov, {'name':'string', 'gender':'string', 'birth_year':'int', 'death_year':'int'})\n",
    "persons_geov.reset_index(inplace=True)\n",
    "\n",
    "print('Geovistory\\'s persons:')\n",
    "tk.infos(persons_geov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHP's persons:\n",
      "Shape:  (62528, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pk</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>death_year</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44895</td>\n",
       "      <td>antoine sainte-marie perrin</td>\n",
       "      <td>Male</td>\n",
       "      <td>1870</td>\n",
       "      <td>1930</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47015</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Male</td>\n",
       "      <td>1506</td>\n",
       "      <td>1545</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47190</td>\n",
       "      <td>alberto duimio</td>\n",
       "      <td>Male</td>\n",
       "      <td>1510</td>\n",
       "      <td>1564</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>47190</td>\n",
       "      <td>albertus divini</td>\n",
       "      <td>Male</td>\n",
       "      <td>1510</td>\n",
       "      <td>1564</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>47578</td>\n",
       "      <td>angelo zampa</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1575</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     pk                         name gender  birth_year  death_year  \\\n",
       "0      0  44895  antoine sainte-marie perrin   Male        1870        1930   \n",
       "1      1  47015                         <NA>   Male        1506        1545   \n",
       "2      2  47190               alberto duimio   Male        1510        1564   \n",
       "3      3  47190              albertus divini   Male        1510        1564   \n",
       "4      4  47578                 angelo zampa   Male        <NA>        1575   \n",
       "\n",
       "  dataset  \n",
       "0     bhp  \n",
       "1     bhp  \n",
       "2     bhp  \n",
       "3     bhp  \n",
       "4     bhp  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "persons_bhp = pd.read_csv('../../data/prepared_persons-bhp.csv', sep=';')\n",
    "tk.set_types(persons_bhp, {'name':'string', 'gender':'string', 'birth_year':'int', 'death_year':'int'})\n",
    "persons_bhp.reset_index(inplace=True)\n",
    "\n",
    "print('BHP\\'s persons:')\n",
    "tk.infos(persons_bhp.drop(columns=['first_name', 'last_name']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction generation blocking rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the set blocking rules to generate the pairwise comparisons; in other words all record couples that do not statisfied at least one of those rules will not be considered in final predictions. \n",
    "\n",
    "This is so to avoid to have to do all comparisons which would be heavy (would take forever) for a computer to do. In our case it would be length of BHP data times length of Geovistory data times number of column, so 62k times 147k times 4 = 37G comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking rule: <l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3>\n",
      "Blocking rule: <l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3>\n"
     ]
    }
   ],
   "source": [
    "blocking_rules_predictions = [\n",
    "    \"l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3\",\n",
    "    \"l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3\",\n",
    "]\n",
    "\n",
    "for br in blocking_rules_predictions:\n",
    "    print(f\"Blocking rule: <{br}>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set multiple comparison rules, which describe how the comparison will be executed on 2 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Comparison Exact match vs. levenshtein at threshold 3 vs. anything else with 3 levels at 0x7f3e2dc780a0>\n",
      "<Comparison Exact match vs. anything else with 2 levels at 0x7f3e2dc784c0>\n",
      "<Comparison Exact match vs. anything else with 2 levels at 0x7f3e2dc783d0>\n",
      "<Comparison Exact match vs. anything else with 2 levels at 0x7f3e2dc78a60>\n"
     ]
    }
   ],
   "source": [
    "comparisons = [\n",
    "    # cl.levenshtein_at_thresholds(\"name\", 1), # Because we want matches with only a typo be more close to a matching than is it is another spelling\n",
    "    cl.levenshtein_at_thresholds(\"name\", 3), # If a name has another spelling (like phonetics)\n",
    "    cl.exact_match(\"gender\"), # Because we have controlled vocabulary for the gender\n",
    "    cl.exact_match(\"birth_year\"), # This takes the assumption that there is no typo possible on birth year\n",
    "    cl.exact_match(\"death_year\"), # This takes the assumption that there is no typo possible on death year\n",
    "]\n",
    "\n",
    "for br in comparisons:\n",
    "    print(f\"{br}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"link_type\": \"link_only\", # Describe the fact that we want to merge 2 dataframe and that one may already have some of the second one.\n",
    "    \"unique_id_column_name\": \"index\", # Each dataframe has to have a unique key for each line, here we tell Splink, what is the name of the column\n",
    "    \"blocking_rules_to_generate_predictions\": blocking_rules_predictions,\n",
    "    \"comparisons\": comparisons,\n",
    "    \"retain_matching_columns\": True, # To have waterfall charts\n",
    "    \"retain_intermediate_calculation_columns\": True, # To have waterfall charts\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chart displays how much final comparisons the model will have to predict. Basically this total number will be an upper boundary of the final prediction table length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-37b02af8e8c0406ebc24b4f3fb7696bb\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-37b02af8e8c0406ebc24b4f3fb7696bb\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-37b02af8e8c0406ebc24b4f3fb7696bb\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"width\": 450, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"data\": {\"values\": [{\"row_count\": 1125, \"rule\": \"l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3\", \"cumulative_rows\": 1125, \"cartesian\": 9231884032, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 1.0. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 0}, {\"row_count\": 2, \"rule\": \"l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3\", \"cumulative_rows\": 1127, \"cartesian\": 9231884032, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 1.0. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 1125}]}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"title\": \"Comparisons Generated by Rule(s)\", \"field\": \"start\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"rule\", \"title\": \"SQL Blocking Rule\", \"sort\": [\"-x2\"]}, \"color\": {\"field\": \"rule\", \"legend\": null, \"scale\": {\"scheme\": \"category20c\"}}, \"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"rule\", \"title\": \"SQL Condition\"}, {\"type\": \"quantitative\", \"field\": \"row_count\", \"title\": \"Comparisons Generated\", \"format\": \",\"}, {\"type\": \"quantitative\", \"field\": \"cumulative_rows\", \"title\": \"Cumulative Comparisons\", \"format\": \",\"}, {\"type\": \"quantitative\", \"field\": \"cartesian\", \"title\": \"Cartesian Product of Input Data\", \"format\": \",\"}, {\"type\": \"nominal\", \"field\": \"reduction_ratio\", \"title\": \"Reduction Ratio (cumulative rows/cartesian product)\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "<splink.charts.VegaliteNoValidate at 0x7f3e806207f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker = DuckDBLinker(\n",
    "    [persons_geov, persons_bhp], \n",
    "    settings, \n",
    "    input_table_aliases=[\"geov\", \"bhp\"] # To have custom names in comparison table\n",
    ")\n",
    "\n",
    "linker.cumulative_num_comparisons_from_blocking_rules_chart()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training blocking rule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train our model, we need to estimate the $m$ and $u$ parameters of the Fellegi-Sunter model associated with and EM algorithm (more of that [here](https://www.robinlinacre.com/maths_of_fellegi_sunter/) and [here](https://www.robinlinacre.com/em_intuition/)).\n",
    "\n",
    "The $u$ parameter will be estimated using random sampling. This is valid (as explained [here](https://moj-analytical-services.github.io/splink/linker.html#splink.linker.Linker.estimate_u_using_random_sampling)) because there is a very low probability for 2 randomly picked records to be the same person. We just have to make sure that the sample taken is large enough to correctly train this parameter.\n",
    "\n",
    "For the $m$ parameter, to have a powerfull model, we can not take such an hypothesis; we need to train the model (statistically) on the data. As before, since we can not take the full data, we need to filter out comparisons so that it is manageable in a reasonnable time. See the next display to see rules we took. \n",
    "\n",
    "How to interpret those rules? Basically, for all column (present in the comparison rules above) not being in a training blocking rules, we will estimate the $m$ parameter on pairwise comparisons validated by the rule. In other word, if the `gender` column does not appear in the rule, it means that the $m$ parameter for the column `gender` will be trained (calculated) on all the pairwaise comparisons remaining after beeing filter by the rule.\n",
    "\n",
    "This also implies that all columns MUST not appear in at least one rule, otherwise we can never train the $m$ parameter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training blocking rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocking rule: <l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3>\n",
      "Blocking rule: <l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3>\n",
      "Blocking rule: <l.birth_year = r.birth_year and l.death_year = r.death_year>\n"
     ]
    }
   ],
   "source": [
    "blocking_rules_training = [\n",
    "    \"l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3\",\n",
    "    \"l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3\",\n",
    "    \"l.birth_year = r.birth_year and l.death_year = r.death_year\",\n",
    "]\n",
    "\n",
    "for br in blocking_rules_training:\n",
    "    print(f\"Blocking rule: <{br}>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n",
      "u probability not trained for name - Exact match (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - name (some u values are not trained, no m values are trained).\n",
      "    - gender (no m values are trained).\n",
      "    - birth_year (no m values are trained).\n",
      "    - death_year (no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.birth_year = r.birth_year and levenshtein(l.name, r.name) <= 3\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - gender\n",
      "    - death_year\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - name\n",
      "    - birth_year\n",
      "\n",
      "Iteration 1: Largest change in params was 0.169 in the m_probability of gender, level `All other comparisons`\n",
      "Iteration 2: Largest change in params was -0.0244 in the m_probability of gender, level `Exact match`\n",
      "Iteration 3: Largest change in params was 0.00101 in the m_probability of death_year, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was -0.000266 in the m_probability of death_year, level `Exact match`\n",
      "Iteration 5: Largest change in params was 6.36e-05 in the m_probability of death_year, level `All other comparisons`\n",
      "\n",
      "EM converged after 5 iterations\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - name (some u values are not trained, no m values are trained).\n",
      "    - birth_year (no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.death_year = r.death_year and levenshtein(l.name, r.name) <= 3\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - gender\n",
      "    - birth_year\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - name\n",
      "    - death_year\n",
      "\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 1: Largest change in params was 0.245 in the m_probability of gender, level `Exact match`\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 2: Largest change in params was 0.00211 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 3: Largest change in params was 0.00183 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 4: Largest change in params was 0.00158 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 5: Largest change in params was 0.00135 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 6: Largest change in params was 0.00114 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 7: Largest change in params was 0.000963 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 8: Largest change in params was 0.000807 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 9: Largest change in params was 0.000673 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 10: Largest change in params was 0.00056 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 11: Largest change in params was 0.000464 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 12: Largest change in params was 0.000384 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 13: Largest change in params was 0.000317 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 14: Largest change in params was 0.000261 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 15: Largest change in params was 0.000215 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 16: Largest change in params was 0.000177 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 17: Largest change in params was 0.000145 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 18: Largest change in params was 0.000119 in probability_two_random_records_match\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison gender not observed in dataset, unable to train m value\n",
      "Iteration 19: Largest change in params was 9.78e-05 in probability_two_random_records_match\n",
      "\n",
      "EM converged after 19 iterations\n",
      "m probability not trained for gender - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - name (some u values are not trained, no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.birth_year = r.birth_year and l.death_year = r.death_year\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - name\n",
      "    - gender\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - birth_year\n",
      "    - death_year\n",
      "\n",
      "Iteration 1: Largest change in params was 0.888 in the m_probability of name, level `All other comparisons`\n",
      "Iteration 2: Largest change in params was 0.00773 in the m_probability of gender, level `Exact match`\n",
      "Iteration 3: Largest change in params was 0.00531 in the m_probability of gender, level `Exact match`\n",
      "Iteration 4: Largest change in params was 0.00379 in the m_probability of gender, level `Exact match`\n",
      "Iteration 5: Largest change in params was -0.00277 in the m_probability of gender, level `All other comparisons`\n",
      "Iteration 6: Largest change in params was 0.00208 in the m_probability of gender, level `Exact match`\n",
      "Iteration 7: Largest change in params was -0.0016 in the m_probability of gender, level `All other comparisons`\n",
      "Iteration 8: Largest change in params was 0.00126 in the m_probability of gender, level `Exact match`\n",
      "Iteration 9: Largest change in params was 0.00102 in the m_probability of gender, level `Exact match`\n",
      "Iteration 10: Largest change in params was -0.000854 in the m_probability of gender, level `All other comparisons`\n",
      "Iteration 11: Largest change in params was 0.000735 in the m_probability of gender, level `Exact match`\n",
      "Iteration 12: Largest change in params was -0.000707 in probability_two_random_records_match\n",
      "Iteration 13: Largest change in params was -0.000713 in probability_two_random_records_match\n",
      "Iteration 14: Largest change in params was -0.000719 in probability_two_random_records_match\n",
      "Iteration 15: Largest change in params was -0.000722 in probability_two_random_records_match\n",
      "Iteration 16: Largest change in params was -0.000726 in probability_two_random_records_match\n",
      "Iteration 17: Largest change in params was -0.000728 in probability_two_random_records_match\n",
      "Iteration 18: Largest change in params was -0.000731 in probability_two_random_records_match\n",
      "Iteration 19: Largest change in params was -0.000733 in probability_two_random_records_match\n",
      "Iteration 20: Largest change in params was -0.000734 in probability_two_random_records_match\n",
      "Iteration 21: Largest change in params was -0.000736 in probability_two_random_records_match\n",
      "Iteration 22: Largest change in params was -0.000737 in probability_two_random_records_match\n",
      "Iteration 23: Largest change in params was -0.000739 in probability_two_random_records_match\n",
      "Iteration 24: Largest change in params was -0.00074 in probability_two_random_records_match\n",
      "Iteration 25: Largest change in params was -0.000741 in probability_two_random_records_match\n",
      "\n",
      "EM converged after 25 iterations\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - name (some u values are not trained).\n"
     ]
    }
   ],
   "source": [
    "z = linker.estimate_u_using_random_sampling(target_rows=2e7)\n",
    "\n",
    "for br in blocking_rules_training:\n",
    "    z = linker.estimate_parameters_using_expectation_maximisation(br)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What has been learned?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model trained, first, lets look at what did the model learn about our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-dde88635775743e48398da56fb3a88da\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dde88635775743e48398da56fb3a88da\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dde88635775743e48398da56fb3a88da\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"width\": 400, \"height\": 60}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}, \"header\": {\"title\": null}}, \"data\": {\"values\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.00010001000100010001, \"log2_bayes_factor\": -13.287568102831404, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.000 or one in  10,000.0 records.This is equivalent to a starting match weight of -13.288.\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": -1}, {\"comparison_name\": \"name\", \"sql_condition\": \"\\\"name_l\\\" = \\\"name_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.06128957219100272, \"u_probability\": 0.000927734375, \"m_probability_description\": \"Amongst matching record comparisons, 6.13% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.09% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 66.06370728798609, \"log2_bayes_factor\": 6.045786026301895, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 66.06 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 0}, {\"comparison_name\": \"name\", \"sql_condition\": \"levenshtein(\\\"name_l\\\", \\\"name_r\\\") <= 3\", \"label_for_charts\": \"Levenshtein <= 3\", \"m_probability\": 0.022772406878377362, \"u_probability\": 3.7522325783841384e-06, \"m_probability_description\": \"Amongst matching record comparisons, 2.28% of records are in the levenshtein <= 3 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.00% of records are in the levenshtein <= 3 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 6069.028612342594, \"log2_bayes_factor\": 12.567249906859182, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenshtein <= 3` then comparison is 6,069.03 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 0}, {\"comparison_name\": \"name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.9159380209306199, \"u_probability\": 0.9999962477674216, \"m_probability_description\": \"Amongst matching record comparisons, 91.59% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 100.00% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.9159414577559977, \"log2_bayes_factor\": -0.12667270322903604, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  1.09 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 0}, {\"comparison_name\": \"gender\", \"sql_condition\": \"\\\"gender_l\\\" = \\\"gender_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.8503161829862032, \"u_probability\": 0.6355693999521997, \"m_probability_description\": \"Amongst matching record comparisons, 85.03% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 63.56% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1.3378809348753327, \"log2_bayes_factor\": 0.41994972860400526, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1.34 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 1}, {\"comparison_name\": \"gender\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1971571447108797, \"u_probability\": 0.36443060004780026, \"m_probability_description\": \"Amongst matching record comparisons, 19.72% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 36.44% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.5410005215945635, \"log2_bayes_factor\": -0.88629810988975, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  1.85 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 1}, {\"comparison_name\": \"birth_year\", \"sql_condition\": \"\\\"birth_year_l\\\" = \\\"birth_year_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.9379141302807048, \"u_probability\": 0.0026337266347641435, \"m_probability_description\": \"Amongst matching record comparisons, 93.79% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.26% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 356.11673508579497, \"log2_bayes_factor\": 8.47620642400977, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 356.12 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 2}, {\"comparison_name\": \"birth_year\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.062085869719295236, \"u_probability\": 0.9973662733652359, \"m_probability_description\": \"Amongst matching record comparisons, 6.21% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.74% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06224981872488019, \"log2_bayes_factor\": -4.0057865538003865, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  16.06 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 2}, {\"comparison_name\": \"death_year\", \"sql_condition\": \"\\\"death_year_l\\\" = \\\"death_year_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.9341517167687721, \"u_probability\": 0.0014514625959738407, \"m_probability_description\": \"Amongst matching record comparisons, 93.42% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.15% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 643.5933790922215, \"log2_bayes_factor\": 9.330005674319692, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 643.59 times more likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 3}, {\"comparison_name\": \"death_year\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06584828323122789, \"u_probability\": 0.9985485374040262, \"m_probability_description\": \"Amongst matching record comparisons, 6.58% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.85% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06594399847844831, \"log2_bayes_factor\": -3.9226148230858446, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.16 times less likely to be a match\", \"probability_two_random_records_match\": 0.0001, \"comparison_sort_order\": 3}]}, \"vconcat\": [{\"height\": 20, \"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}], \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight\", \"scale\": {\"range\": [\"red\", \"orange\", \"green\"], \"domain\": [-10, 0, 10]}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"comparison_name\", \"title\": \"Comparison name\"}, {\"type\": \"nominal\", \"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Equivalent match weight\", \"format\": \",.4f\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"labels\": false, \"domain\": false, \"title\": \"\", \"ticks\": false}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}}, \"y\": {\"type\": \"nominal\", \"field\": \"label_for_charts\", \"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAngle\": 0, \"titleAlign\": \"right\", \"titleFontWeight\": \"normal\"}, \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}}}}, {\"height\": {\"step\": 12}, \"mark\": {\"type\": \"bar\", \"clip\": true}, \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}], \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight\", \"scale\": {\"range\": [\"red\", \"orange\", \"green\"], \"domain\": [-10, 0, 10]}}, \"row\": {\"type\": \"nominal\", \"field\": \"comparison_name\", \"sort\": {\"field\": \"comparison_sort_order\"}, \"header\": {\"labelAngle\": 0, \"labelAnchor\": \"middle\", \"labelAlign\": \"left\"}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"comparison_name\", \"title\": \"Comparison name\"}, {\"type\": \"ordinal\", \"field\": \"label_for_charts\", \"title\": \"Label\"}, {\"type\": \"nominal\", \"field\": \"sql_condition\", \"title\": \"SQL condition\"}, {\"type\": \"quantitative\", \"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\"}, {\"type\": \"quantitative\", \"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\"}, {\"type\": \"quantitative\", \"field\": \"bayes_factor\", \"title\": \"Bayes factor = m/u\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight = log2(m/u)\", \"format\": \",.4f\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}}, \"y\": {\"type\": \"nominal\", \"field\": \"label_for_charts\", \"axis\": {\"title\": null}, \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}}}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}}], \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.2.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "<splink.charts.VegaliteNoValidate at 0x7f3e80614a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe how a response level (on the left) influences the matching probability.\n",
    "\n",
    "More particularly we observe that the gender has a very low influence on the result, just on the contrary of the name."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persons identified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table is an extract of the 50 most probable matchings.\n",
    "Each line represents a pairwise comparison. We can see the probability (computed by the trained model), and each column put aside another in order to be more human readable. A copy is available as a CSV table in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'name':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result number: 1127\n"
     ]
    }
   ],
   "source": [
    "# results = linker.predict(threshold_match_probability=0.9)\n",
    "results = linker.predict()\n",
    "results_df = results.as_pandas_dataframe().sort_values(by='match_probability', ascending=False)\n",
    "print('Result number:', len(results_df))\n",
    "\n",
    "readable = results_df[['match_probability', 'source_dataset_l', 'source_dataset_r', 'index_l', 'index_r', 'name_l', 'name_r', 'gender_l', 'gender_r', 'birth_year_l', 'birth_year_r', 'death_year_l', 'death_year_r']].copy()\n",
    "readable.rename(columns={\n",
    "    'match_probability':'proba', \n",
    "    'index_l': 'index_bhp', \n",
    "    'index_r': 'index_geov',\n",
    "    'name_l': 'bhp_name',\n",
    "    'name_r': 'geov_name',\n",
    "    'gender_l': 'bhp_gender',\n",
    "    'gender_r': 'geov_gender',\n",
    "    'birth_year_l': 'bhp_birth_year',\n",
    "    'birth_year_r': 'geov_birth_year',\n",
    "    'death_year_l': 'bhp_death_year',\n",
    "    'death_year_r': 'geov_death_year'\n",
    "}, inplace=True)\n",
    "tk.set_types(readable, {\n",
    "    'bhp_birth_year': 'int',\n",
    "    'geov_birth_year': 'int',\n",
    "    'bhp_death_year': 'int',\n",
    "    'geov_death_year': 'int',\n",
    "})\n",
    "readable['proba'] = [tk.percent(p) for p in readable['proba']]\n",
    "readable.drop(columns=['source_dataset_l', 'source_dataset_r'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1079, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>pk_bhp</th>\n",
       "      <th>pk_geov</th>\n",
       "      <th>bhp_name</th>\n",
       "      <th>geov_name</th>\n",
       "      <th>bhp_gender</th>\n",
       "      <th>geov_gender</th>\n",
       "      <th>bhp_birth_year</th>\n",
       "      <th>geov_birth_year</th>\n",
       "      <th>bhp_death_year</th>\n",
       "      <th>geov_death_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>640</td>\n",
       "      <td>1645449</td>\n",
       "      <td>francesco tedeschini piccolomini</td>\n",
       "      <td>francesco todeschini piccolomini</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>1439</td>\n",
       "      <td>1439</td>\n",
       "      <td>1503</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>53464</td>\n",
       "      <td>869278</td>\n",
       "      <td>jean andré de luc</td>\n",
       "      <td>jean-andré deluc</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1727</td>\n",
       "      <td>1727</td>\n",
       "      <td>1817</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>1000</td>\n",
       "      <td>899892</td>\n",
       "      <td>pierre-daniel huet</td>\n",
       "      <td>pierre daniel huet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1630</td>\n",
       "      <td>1630</td>\n",
       "      <td>1721</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>200</td>\n",
       "      <td>27035</td>\n",
       "      <td>johann caspar lavater</td>\n",
       "      <td>johann kaspar lavater</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1741</td>\n",
       "      <td>1741</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00%</td>\n",
       "      <td>215</td>\n",
       "      <td>913686</td>\n",
       "      <td>martin luder</td>\n",
       "      <td>martin luther</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1483</td>\n",
       "      <td>1483</td>\n",
       "      <td>1546</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     proba  pk_bhp  pk_geov                          bhp_name  \\\n",
       "0  100.00%     640  1645449  francesco tedeschini piccolomini   \n",
       "1  100.00%   53464   869278                 jean andré de luc   \n",
       "2  100.00%    1000   899892                pierre-daniel huet   \n",
       "3  100.00%     200    27035             johann caspar lavater   \n",
       "4  100.00%     215   913686                      martin luder   \n",
       "\n",
       "                          geov_name bhp_gender geov_gender  bhp_birth_year  \\\n",
       "0  francesco todeschini piccolomini       Male        Male            1439   \n",
       "1                  jean-andré deluc       Male         NaN            1727   \n",
       "2                pierre daniel huet        NaN         NaN            1630   \n",
       "3             johann kaspar lavater        NaN         NaN            1741   \n",
       "4                     martin luther        NaN         NaN            1483   \n",
       "\n",
       "   geov_birth_year  bhp_death_year  geov_death_year  \n",
       "0             1439            1503             1503  \n",
       "1             1727            1817             1817  \n",
       "2             1630            1721             1721  \n",
       "3             1741            1801             1801  \n",
       "4             1483            1546             1546  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make the link against private keys of BHP and GEOV\n",
    "readable = readable.merge(persons_bhp[['index', 'pk']], left_on='index_bhp', right_on='index', how='left').rename(columns={'pk': 'pk_bhp'}).drop(columns=['index'])\n",
    "readable = readable.merge(persons_geov[['index', 'pk']], left_on='index_geov', right_on='index', how='left').rename(columns={'pk': 'pk_geov'}).drop(columns=['index'])\n",
    "readable = readable[['proba', 'pk_bhp', 'pk_geov', 'bhp_name', 'geov_name', 'bhp_gender', 'geov_gender', 'bhp_birth_year', 'geov_birth_year', 'bhp_death_year', 'geov_death_year']]\n",
    "\n",
    "readable.drop_duplicates(subset=['pk_bhp', 'pk_geov'], inplace=True)\n",
    "\n",
    "readable.to_csv('../../data/record-linkage_bhp-geov.csv', sep=\";\", index=False, quoting=2)\n",
    "tk.infos(readable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chart gives us details about a particular pairwise comparison. The example can be changed with the bottom slider. More information are available on mouse over the different elements.\n",
    "\n",
    "This chart helps us understand why the model answered the provided response.\n",
    "\n",
    "For conveniance, only the first 1000 comparisons are available through this chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_to_plot = results_df.head(1000).to_dict(orient=\"records\")\n",
    "linker.waterfall_chart(records_to_plot, filter_nulls=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
