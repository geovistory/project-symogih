{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "env = 'prod'\n",
    "pk_project = 6857901\n",
    "execute = True\n",
    "metadata_str = 'bhp-actors-births'\n",
    "import_manner = 'batch'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "import plotly.express as px\n",
    "\n",
    "import geovpylib.analysis as a\n",
    "import geovpylib.database as db\n",
    "import geovpylib.graphs as graphs\n",
    "import geovpylib.pks as pks\n",
    "import geovpylib.recordlinkage as rl\n",
    "import geovpylib.sparql as sparql\n",
    "import geovpylib.utils as u\n",
    "\n",
    "eta = u.Eta()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth and death date complements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf [GitHub Issue \"Import actors - Fields\"](https://github.com/geovistory/symogih/issues/6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Geovistory data: pk BHP <=> pk Geovistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Connecting to PRODUCTION Database ... Connected!\n",
      "Shape:  (59655, 4) - extract:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk_bhp</th>\n",
       "      <th>pk_gv</th>\n",
       "      <th>pk_birth</th>\n",
       "      <th>pk_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6532778</td>\n",
       "      <td>7489054</td>\n",
       "      <td>7726515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6499432</td>\n",
       "      <td>7489055</td>\n",
       "      <td>7726516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>783602</td>\n",
       "      <td>806773</td>\n",
       "      <td>7726517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6509333</td>\n",
       "      <td>7489056</td>\n",
       "      <td>7726518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6511070</td>\n",
       "      <td>7489057</td>\n",
       "      <td>7726519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pk_bhp    pk_gv  pk_birth  pk_death\n",
       "0       1  6532778   7489054   7726515\n",
       "1       2  6499432   7489055   7726516\n",
       "2       3   783602    806773   7726517\n",
       "3       4  6509333   7489056   7726518\n",
       "4       5  6511070   7489057   7726519"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Database correctly disconnected.\n"
     ]
    }
   ],
   "source": [
    "db.connect_geovistory(env, pk_project, execute, skip_protection=True)\n",
    "\n",
    "persons = db.query(f\"\"\"\n",
    "    select distinct\n",
    "        r.pk_entity as pk_gv,\n",
    "        a3.string as uri,\n",
    "        s4.fk_subject_info as pk_birth,\n",
    "        --s4b.pk_entity as pk_stmt_birth_to_date,\n",
    "        --tp4.julian_day as julian_day_birth,\n",
    "        --tp4.calendar as calendar_date_birth,\n",
    "        --ipr4b.is_in_project as iip_birth,\n",
    "        s5.fk_subject_info as pk_death--,\n",
    "        --s5b.pk_entity as pk_stmt_death_to_date,\n",
    "        --tp5.julian_day as julian_day_death,\n",
    "        --tp5.calendar as calendar_date_death,\n",
    "        --ipr5b.is_in_project as iip_death\n",
    "    from information.resource r\n",
    "    inner join projects.info_proj_rel ipr on ipr.fk_entity = r.pk_entity and ipr.fk_project = {pk_project} and ipr.is_in_project = true\n",
    "    -- URI\n",
    "    inner join information.statement s1 on s1.fk_subject_info = r.pk_entity and s1.fk_property = {pks.properties.entity_sameAsURI_URI}\n",
    "    inner join projects.info_proj_rel ipr1 on ipr1.fk_entity = s1.pk_entity and ipr1.fk_project = {pk_project} and ipr1.is_in_project = true\n",
    "    inner join information.statement s2 on s2.fk_subject_info = s1.fk_object_info and s2.fk_property = {pks.properties.appe_hasValue_string}\n",
    "    inner join projects.info_proj_rel ipr2 on ipr2.fk_entity = s2.pk_entity and ipr2.fk_project = {pk_project} and ipr2.is_in_project = true\n",
    "    inner join information.appellation a3 on a3.pk_entity = s2.fk_object_info\n",
    "    inner join projects.info_proj_rel ipr3 on ipr3.fk_entity = a3.pk_entity and ipr3.fk_project = {pk_project} and ipr3.is_in_project = true\n",
    "    -- Birth\n",
    "    left join information.statement s4 on s4.fk_object_info = r.pk_entity and s4.fk_property = {pks.properties.birth_broughtIntoLife_person}\n",
    "    inner join projects.info_proj_rel ipr4 on ipr4.fk_entity = s4.pk_entity and ipr4.fk_project = {pk_project} and ipr4.is_in_project = true\n",
    "    --left join information.statement s4b on s4b.fk_subject_info = s4.fk_subject_info and s4b.fk_property = {pks.properties.timeSpan_atSomeTimeWithin_timePrimitive}\n",
    "    --left join projects.info_proj_rel ipr4b on ipr4b.fk_entity = s4b.pk_entity and ipr4b.fk_project = {pk_project} and ipr4b.is_in_project = true\n",
    "    --left join information.time_primitive tp4 on tp4.pk_entity = s4b.fk_object_info\n",
    "    -- Death\n",
    "    left join information.statement s5 on s5.fk_object_info = r.pk_entity and s5.fk_property = {pks.properties.death_wasDeathOf_person}\n",
    "    inner join projects.info_proj_rel ipr5 on ipr5.fk_entity = s5.pk_entity and ipr5.fk_project = {pk_project} and ipr5.is_in_project = true\n",
    "    --left join information.statement s5b on s5b.fk_subject_info = s5.fk_subject_info and s5b.fk_property = {pks.properties.timeSpan_atSomeTimeWithin_timePrimitive}\n",
    "    --left join projects.info_proj_rel ipr5b on ipr5b.fk_entity = s5b.pk_entity and ipr5b.fk_project = {pk_project} and ipr5b.is_in_project = true\n",
    "    --left join information.time_primitive tp5 on tp5.pk_entity = s5b.fk_object_info\n",
    "\n",
    "    where r.fk_class = {pks.classes.person}\n",
    "\"\"\")\n",
    "persons = persons[persons.uri.str.contains('symogih.org')]\n",
    "persons['pk_bhp'] = persons.uri.str.replace('http://symogih.org/resource/Actr', '', regex=False).astype(int)\n",
    "persons.drop(columns=['uri'], inplace=True)\n",
    "\n",
    "persons.sort_values('pk_bhp', inplace=True)\n",
    "persons.drop_duplicates(inplace=True)\n",
    "persons.reset_index(inplace=True, drop=True)\n",
    "persons = persons[['pk_bhp', 'pk_gv', 'pk_birth', 'pk_death']].drop_duplicates()\n",
    "\n",
    "a.infos(persons)\n",
    "db.disconnect()\n",
    "\n",
    "# 12s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch those dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Connecting to PGSQL Database ... Connected!\n",
      "Information nb: 258\n",
      "[DB] Database correctly disconnected.\n"
     ]
    }
   ],
   "source": [
    "db.connect_external(os.environ.get('YELLOW_BHP'))\n",
    "\n",
    "births_deaths_bhp = db.query(f\"\"\"\n",
    "    select \n",
    "        ir.fk_associated_object as pk_bhp,\n",
    "        ir.fk_information as fk_info,\n",
    "        id.year, id.month, id.day,\n",
    "        id.fk_abob_type_information_date,\n",
    "        ir.fk_type_role\n",
    "    from bhp.information_role ir\n",
    "    inner join bhp.information_date id on ir.fk_information = id.fk_information\n",
    "    where ir.fk_type_role = 40 or ir.fk_type_role = 45\n",
    "\"\"\")\n",
    "\n",
    "births_deaths_bhp = births_deaths_bhp[pd.notna(births_deaths_bhp['pk_bhp'])]  \n",
    "births_deaths_bhp = births_deaths_bhp[births_deaths_bhp['pk_bhp'].str.contains('Actr')]\n",
    "births_deaths_bhp['pk_bhp'] = births_deaths_bhp['pk_bhp'].str.replace('Actr', '', regex=False)\n",
    "births_deaths_bhp['pk_bhp'] = births_deaths_bhp['pk_bhp'].astype(pd.Int64Dtype())\n",
    "births_deaths_bhp['year'] = births_deaths_bhp['year'].astype(pd.Int64Dtype())\n",
    "births_deaths_bhp['month'] = births_deaths_bhp['month'].astype(pd.Int64Dtype())\n",
    "births_deaths_bhp['day'] = births_deaths_bhp['day'].astype(pd.Int64Dtype())\n",
    "births_deaths_bhp['date_bhp'] = [(row.year, row.month, row.day) for i, row in births_deaths_bhp.iterrows()]\n",
    "births_deaths_bhp['uri_evt'] = ['http://symogih.org/resource/Info' + str(fk_info) for fk_info in births_deaths_bhp['fk_info']]\n",
    "\n",
    "births_deaths_bhp = births_deaths_bhp[(births_deaths_bhp['fk_abob_type_information_date'] == 1125) | (births_deaths_bhp['fk_abob_type_information_date'] == 1126)]\n",
    "\n",
    "print('Information nb:', len(births_deaths_bhp))\n",
    "\n",
    "db.disconnect()\n",
    "\n",
    "# 1s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information nb (after merge): 258\n"
     ]
    }
   ],
   "source": [
    "table = births_deaths_bhp.merge(persons, on='pk_bhp')\n",
    "table['pk_teen'] = [row['pk_birth'] if row['fk_type_role'] == 40 else row['pk_death'] for _,row in table.iterrows()]\n",
    "table['pk_property'] = [pks.properties.timespan_beginOfTheBegin_timePrim if row['fk_abob_type_information_date'] == 1125 else pks.properties.timespan_endOfTheEnd_timePrim for _,row in table.iterrows()]\n",
    "table['date'] = table['date_bhp']\n",
    "\n",
    "print('Information nb (after merge):', len(table))\n",
    "\n",
    "table = table[['pk_teen', 'pk_property', 'date', 'pk_birth', 'pk_death']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Connecting to PRODUCTION Database ... Connected!\n"
     ]
    }
   ],
   "source": [
    "db.connect_geovistory(env, pk_project, execute)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove existing at some time within statements from project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all at some time within properties that needs to be removed from project\n",
    "pks_teen = table['pk_teen'].unique().tolist()\n",
    "values = '(' + ','.join([str(pk) for pk in pks_teen]) + ')'\n",
    "at_some_times_within = db.query(f\"\"\"\n",
    "    select \n",
    "        s.pk_entity as pk_stmt, ipr.pk_entity as pk_ipr\n",
    "    from information.resource r\n",
    "    inner join information.statement s on s.fk_subject_info = r.pk_entity and s.fk_property = {pks.properties.timeSpan_atSomeTimeWithin_timePrimitive}\n",
    "    inner join projects.info_proj_rel ipr on ipr.fk_entity = s.pk_entity and ipr.fk_project = {pk_project} and ipr.is_in_project = true\n",
    "    where r.pk_entity in {values}\n",
    "\"\"\")\n",
    "\n",
    "values_ipr = '(' + ','.join([str(pk) for pk in at_some_times_within['pk_ipr'].tolist()]) + ')'\n",
    "\n",
    "db.execute(f\"\"\"\n",
    "    update projects.info_proj_rel\n",
    "        set is_in_project = false           \n",
    "    where pk_entity in {values_ipr};\n",
    "\"\"\")\n",
    "\n",
    "table.drop(columns=['pk_birth', 'pk_death'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new `begin of the begin` & `end of the end` statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 258 time primitives ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 258 entities with project <6857901> ... Done in [00h00'01]\n",
      "Creating 258 statements ... Done in [00h00'00]\n",
      "Creating info_proj_rel of 258 entities with project <6857901> ... Done in [00h00'00]\n"
     ]
    }
   ],
   "source": [
    "def get_duration(date):\n",
    "    if pd.notna(date[0]) and pd.isna(date[1]) and pd.isna(date[2]): return '1 year'\n",
    "    if pd.notna(date[0]) and pd.notna(date[1]) and pd.isna(date[2]): return '1 month'\n",
    "    if pd.notna(date[0]) and pd.notna(date[1]) and pd.notna(date[2]): return '1 day'\n",
    "    return pd.NA\n",
    "\n",
    "table['duration'] = [get_duration(d) for d in table['date']]\n",
    "\n",
    "\n",
    "# Create time primitives\n",
    "table['pk_time_prim'] = db.time_primitives.create(table['date'], table['duration'])\n",
    "\n",
    "# Create statements\n",
    "db.statements.create(table['pk_teen'], table['pk_property'], table['pk_time_prim'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
